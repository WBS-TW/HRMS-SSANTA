[["index.html", "Comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS: a tutorial using R Preface", " Comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS: a tutorial using R Thanh Wang, MTM Research Centre, Örebro University 2020-11-25 Preface This book is a work-in-progress book to introduce the concepts of suspect and nontarget analysis (SSA/NTA) with focus on environmental analytical chemistry and to provide practical demonstrations for a workflow for SSA/NTA. Does not include all the vast number of platforms, software and applications that can be used for SSA/NTA. Includes the use of applications that has been developed by the author. Basic knowledge of R programming is a prerequisite to understand some of the codes The author do not take responsibility for programs or computer crashing. Please cite: "],["Intro.html", "1 Introduction and concepts 1.1 Terminologies", " 1 Introduction and concepts This is italic This is bold Demonstrating subscript: H2SO4 Superscript: 13C Inline code: library(tidyverse) (#fig:target_vs_nontarget)Comparison between target and nontarget analysis Figure 1.1: Knowns and unknowns 1.1 Terminologies - High resolution mass spectrometry - Non-target analysis - Suspect screening analysis - Semi-quantification - Pseudo-quantification - Data-dependent analysis (DDA) - Data-indenpendent analysis (DIA) "],["Exp-design.html", "2 Experimental design 2.1 Hypothesis 2.2 Experimental design 2.3 QA/QC measures 2.4 Sampling design and collection 2.5 Collection of metadata 2.6 Chemical analysis 2.7 Data analysis 2.8 Workflow examples", " 2 Experimental design (#fig:diagram_exp_des)Design workFlow 2.1 Hypothesis xx 2.2 Experimental design - Compounds of interest? - Amendable to GC and/or LC? - Instrumentations available? 2.3 QA/QC measures - Spiking with native before and after extraction to evaluate the extraction efficiency and matrix effect. - Dilute QC extracts to investigate potential matrix effects(?) - Field blanks - Procedural blanks - Solvent blanks - Procedural replicates - Triplicate injections . Should also inject the procedural replicates in triplicates. - Standard reference material - Randomization - Retention time index standard - Volumetric internal standard added into the final extract to guard against small difference of extract volumes.Use e.g. 4,4-Dibromooctafluorobiphenyl which should not be in the samples and is stable. - 2.4 Sampling design and collection xx Whats in a name? Sample names/ID Naming sample IDs might seem trivial at first but could help downstream data analysis and also to clarify your sampling design. It is important to have a uniform naming. convention and that the sample codes could also specify if a sample is a field blank, procedural blank, replicates, belong to a specific group Dont start a sample ID with a number 2.5 Collection of metadata Metadata is the information about data. In this particular case, it is the relevant information about our samples and chemicals of interest. Examples could be the location, group, 2.6 Chemical analysis xx 2.7 Data analysis xx 2.8 Workflow examples (#fig:example_workflows)Workflow for nontarget using XX (#fig:example_identification)Workflow for structure elucidation and identification "],["MS-preprocess.html", "3 Pre-processing HRMS data 3.1 Peak picking 3.2 OpenMS and Toppview 3.3 MsnBase and XCMS 3.4 PatRoon 3.5 MS-DIAL 3.6 Output formats", " 3 Pre-processing HRMS data 3.1 Peak picking (#fig:PFOS isotopes)PFOS isotopic patterns (#fig:peak picking)Mass traces of PFOS and labelled standards ## Alignment ## Componentization ## Proprietary and standardized MS data format See: https://en.wikipedia.org/wiki/Mass_spectrometry_data_format 3.2 OpenMS and Toppview xx https://www.youtube.com/watch?v=GuK1daIc6vo&amp;list=PL2u38g_AG4MH7yCMF06N2VW7eZOJcglh7&amp;index=5 ## MSConvert xx 3.3 MsnBase and XCMS xx 3.4 PatRoon xx https://www.researchsquare.com/article/rs-36675/v1 https://rickhelmus.github.io/patRoon/articles/tutorial.html OpenMS performs peak picking and isotope grouping in one step (any idea how to turn off this?), while XCMS does not perform this step here. From Rick: For OpenMS: you can use a trick for this by setting localMZRange=0, this way OpenMS wont be able to look for isotopes. Note that its detection was more developed for natural compounds (eg proteomics, metabolomics) in mind, and that it isnt really good in grouping halogenated peaks anyway. 3.5 MS-DIAL MS2Dec: Sigma window value: 0.1 - 1.0. Smaller value will avoid clustering of peaks that are far from each other (false positive grouping). MS/MS abundance cut off: increase to remove background noise 3.6 Output formats - MSnExp and XCMSnExp - MSP - MFG - CSV (for both output data or metadata) "],["suspect-screening.html", "4 Suspect screening 4.1 Listing suspects 4.2 Suspect scoring", " 4 Suspect screening 4.1 Listing suspects 4.2 Suspect scoring - Mass error (ppm) - RMS of isotope intensities (%) - RMS of mz error ppm "],["mass-defect.html", "5 Mass defect plots 5.1 MDPlotR 5.2 findhalo", " 5 Mass defect plots This is a chapter about using mass defect plots to help with nontarget data 5.1 MDPlotR xx 5.2 findhalo xx "],["retention-times.html", "6 Retention time index and prediction 6.1 LC", " 6 Retention time index and prediction This is a chapter about retention time index and prediction 6.1 LC xx 6.1.1 Retip - Retention Time prediction for Metabolomics Webpage: https://www.retip.app/ "],["molecular-networks.html", "7 Molecular networks 7.1 MetGem", " 7 Molecular networks This is a chapter about molecular networks 7.1 MetGem xx 7.1.1 GC data xx Metgem webpage: https://metgem.github.io/ Metgem handbook: https://metgem.readthedocs.io/en/latest/index.html A new option was added to the input data file dialogue. When this option is activated, input spectra are treated as MS1, and thus, the parent m/z ratio is fully ignored. The molecular networks were created using MetGem 1.2.2 software (https://metgem.github.io/). EI-MS spectra were window filtered by choosing only the top 6 peaks in the ±50 Da window throughout the spectrum. Cosine scores were calculated using a m/z tolerance of 0.3 Th. Networks were then created where edges were filtered to have a cosine score above 0.7 (or 0.75 in the case of GC-EI-MS data from perfumes) and more than six matched peaks. Furthermore, edges between two nodes were kept in the network if and only if each of the nodes appeared in each others respective top 10 most similar nodes. The library spectra were filtered in the same manner as the input data. "],["library.html", "8 Library search 8.1 NEIMS 8.2 DeepEI 8.3 Other prediction algorithms 8.4 LIBRARY SEARCH", " 8 Library search In environmental analysis, NIST MS library is widely used to match a spectrum to a list of standard spectra. However, a major drawback of the NIST MS Search is that now all chemicals are included and all spectral ions are at unit mass (for EI spectra library, also called mainlib) ## IN SILICO FRAGMENTATION There are three different models that have recently been published to prdict the fragmentation patterns of GC-EI MS. ### MEtfrag 8.0.1 Sirius CSI FingerID 8.0.2 CFM-ID In silico fragmentation: Help file: https://sourceforge.net/p/cfm-id/wiki/Home/ Use instructions: If you are using EI-MS (GC-MS) data, please use the ei_ms_model provided. Note that lpsolve55.dll must also be included in the same directory as the executables. This file can be found in the development version of LPSolve (e.g. lp_solve_5.5.2.0_dev_win32.zip), which can be downloaded from https://sourceforge.net/projects/lpsolve/files/lpsolve/5.5.2.5/lp_solve_5.5.2.5_dev_win32.zip/download. Cfm-predict COMMAND: cfm-predict.exe &lt;smiles_or_inchi_or_file&gt; &lt;prob_thresh&gt; &lt;param_file&gt; &lt;config_file&gt; &lt;annotate_fragments&gt; &lt;output_file_or_dir&gt; &lt;apply_postproc&gt; &lt;suppress_exceptions&gt; EXAMPLE (naphthalene): cfm-predict.exe InChI=1S/C10H8/c1-2-6-10-8-4-3-7-9(10)5-1/h1-8H 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp EXAMPLE (.txt file as input): cfm-predict.exe D:/Program/cfm-id-2.4_win32/test/input.txt 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp 8.1 NEIMS Help files: https://github.com/brain-research/deep-molecular-massspec 8.2 DeepEI Help files: https://github.com/hcji/DeepEI https://github.com/hcji/DeepEI/blob/master/Usage.ipynb 8.3 Other prediction algorithms QCEIMS 8.4 LIBRARY SEARCH xx 8.4.1 LIB2NIST Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass). See command line help file for arguments. COMMAND: lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt; EXAMPLES: lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\LCMs_GC_Orbitrap.msp C:\\NIST14\\ =LCMs_GC_Orbitrap 8.4.2 MSPepSearch Use MSPepSearch to find similar spectra EXAMPLES: MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 10 /OnlyFound /HITS 5 /LIB D:\\Raw_data\\Dust_Florian\\GC\\test\\Mylib /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\input.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv /OutMW MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 100 /OnlyFound /HITS 5 /LIB C:\\NIST14\\NIST_contaminants_orbitrap /INP D:\\Projects\\Mexico_Air\\NIST_Mexico.msp /OUTMGF D:\\Projects\\Mexico_Air\\test\\test.mgf /OUTTAB D:\\Projects\\Mexico_Air\\test\\test.tsv MSPepSearch64.exe Gusviqh /ZI 0.01 /ZIPPM 10 /MPPM 10 /MzLimits 50 -1 /MinMF 500 /OnlyFound /HITS 5 /LIB C:\\NIST14\\LCMs_GC_Orbitrap /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\11.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv "],["postprocessing.html", "9 Data post-processing 9.1 Hierarchical clustering", " 9 Data post-processing ## Classyfire 9.1 Hierarchical clustering "],["example-dust.html", "10 Example workflow: indoor dust", " 10 Example workflow: indoor dust A walkthrough for indoor dust analysis (#fig:example_workflows_dust)Workflow for nontarget using XX This code uses XCMS with MF -&gt; CAMERA preprocessing used in : Stettin, D.; Poulin, R.X.; Pohnert, G. Metabolomics Benefits from Orbitrap GCMSComparison of Low- and High-Resolution GCMS. Metabolites 2020, 10, 143. See the supplementary material for original code. The code was modified here to also include retention time index and also remove zero intensity peaks after peak grouping. Additional metainformation for the msp file can also be added in the extra object. library(processx) library(xcms) library(CAMERA) library(metaMS) library(dplyr) library(stringr) #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/home/ORUNET.ORU.SE/twg/Dioxinlab/GC-Orbitrap data/Florian/Dust NTA 20200513/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;/home/ORUNET.ORU.SE/twg/Windows_home/Dust_Florian/Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) mzXMLfiles &lt;- as.character(sample_info$filename) pd &lt;- data.frame(sample_name = paste0(sample_info$new_codes, &quot;.mzXML&quot;), class = sample_info$group, stringsAsFactors = FALSE) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) min.clustersize &lt;- 17 #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra useOriginalCode(TRUE) #otherwise matchedFilter will allocate a huge amount of RAM when using step = 0.001 #Refer to XCMS and CAMERA documentation for information about parameters and functions #These are the parameters used for high rez GC-Orbitrap data xs1 &lt;- xcmsSet(mzXMLfiles, phenoData = pd, method = &quot;matchedFilter&quot;, fwhm = 3, step = 0.001, steps = 2, max = 1000, snthresh = 3, mzdiff = 0.002) xs2 &lt;- group(xs1, method = &quot;density&quot;, bw = 5, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs3 &lt;- retcor(xs2, method = &quot;obiwarp&quot;) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.6, minsamp = 1, minfrac = 0, max = 1000) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs5 &lt;- fillPeaks(xs4) xs6 &lt;- xsAnnotate(xs = xs5, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;untreated_peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize #you don&#39;t need to modify anything, that run the next part as is peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in pcgroups) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;spectra_MatchedFilter20201030.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra This code uses XCMS with centWave. Check differences and skip first steps to combine both workflows #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample_xcms&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) pd &lt;- data.frame(sample_name = paste0(sample_info$analysis, &quot;.mzXML&quot;), sample_group = sample_info$group, stringsAsFactors = FALSE) mzXMLfiles &lt;- paste0(sample_info$path, &quot;/&quot;, sample_info$analysis, &quot;.mzXML&quot;) # Use subset to test pd &lt;- pd[1:2,] mzXMLfiles &lt;- mzXMLfiles[1:2] raw_data &lt;- readMSData(mzXMLfiles, pdata = new(&quot;NAnnotatedDataFrame&quot;, pd), mode = &quot;onDisk&quot;) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) #-----Find features----# # centWave params cwp &lt;- CentWaveParam(ppm = 5, peakwidth = c(3, 45), snthresh = 10, prefilter = c(1,30000), mzCenterFun = &quot;wMean&quot;, integrate = 1L, mzdiff = -0.001, fitgauss = FALSE, noise = 30000, verboseColumns = FALSE) xs1 &lt;- findChromPeaks(mzXMLfiles, param = cwp) # use model peak to evaluate process rtr &lt;- c(1440, 1460) mzr &lt;- c(340.238, 340.242) chr_raw &lt;- chromatogram(mzXMLfiles, mz = mzr, rt = rtr) chr_mzr &lt;- chromatogram(xs1, mz = mzr, rt = rtr) group_colors &lt;- paste0(brewer.pal(3, &quot;Set1&quot;)[1:2], &quot;60&quot;) sample_colors &lt;- group_colors[xs1$sample_group] #----Group features 1----# pdp &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 10, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs2 &lt;- groupChromPeaks(xs1, param = pdp) plotChromPeakDensity(chr_mzr, col = sample_colors, param = pdp) #----retention time correction----# obip &lt;- ObiwarpParam(binSize = 0.05, # need to check optimal binSize centerSample = integer(), response = 1L, distFun = &quot;cor_opt&quot;, gapInit = numeric(), gapExtend = numeric(), factorDiag = 2, factorGap = 1, localAlignment = FALSE, initPenalty = 0, subset = integer(), subsetAdjust = c(&quot;average&quot;, &quot;previous&quot;)) xs3 &lt;- adjustRtime(xs2, param = obip) # Get the base peak chromatograms bpis_adj &lt;- chromatogram(xs3, aggregationFun = &quot;max&quot;, include = &quot;none&quot;) par(mfrow = c(2, 1), mar = c(4.5, 4.2, 1, 0.5)) plot(bpis_adj) # Plot also the difference of adjusted to raw retention time. plotAdjustedRtime(xs3) par(mfrow = c(2, 1)) ## Plot the raw data plot(chr_raw) ## Extract the chromatogram from the adjusted object chr_adj &lt;- chromatogram(xs3, rt = rtr, mz = mzr) plot(chr_adj, peakType = &quot;none&quot;) #----Group features 2----# # After retention time correction, the rt values are modified and additional grouping is needed. pdp2 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 5, minFraction = 0, minSamples = 1, binSize = 0.2, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs3, param = pdp2) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp2) # iteratively decrease the binSize pdp3 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 2, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs4, param = pdp3) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp3) #----Fill missing features----# xs5 &lt;- fillChromPeaks(xs4) ## Check missing values before filling in peaks apply(featureValues(xs5, filled = FALSE), MARGIN = 2, FUN = function(z) sum(is.na(z))) ## Missing values after filling in peaks apply(featureValues(xs5), MARGIN = 2, FUN = function(z) sum(is.na(z))) #---- QC ----# # Extract chromatograms of 4 features feature_chroms &lt;- featureChromatograms(xs5, features = 10000:10004) plot(feature_chroms) boxplot(featureValues(xs5, value=&quot;into&quot;) +1, #col=as.numeric(sampclass(mtbls2Set))+1, log=&quot;y&quot;, las=2) sdThresh &lt;- 4.0 ## Filter low-standard deviation rows for plot data &lt;- log(featureValues(xs5))+1 pca.result &lt;- pca(data, nPcs=3) plotPcs(pca.result, type=&quot;loadings&quot;, #col=as.numeric(sampclass(mtbls2Set))+1 ) # It is possible to use the retention time correction and grouping step in an iterative way if needed. # Once you perform your last adjustRtime step and thus your last grouping step, you will obtain your final peak list (i.e. final list of ions) #----Annotation using CAMERA----# # Since CAMERA has not yet been ported to XCMSnExp,we need to convert to xcmsSet. # Note that the conversion only makes sense for somple XCMSnSets, # without e.g. MS level filtering (where CAMERA would then extract the wrong peaks) xs6 &lt;- as(xs5, &quot;xcmsSet&quot;) xs6 &lt;- xsAnnotate(xs = xs6, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra min.clustersize &lt;- 20 peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) # Replaces NA in intensities with zero peaktable &lt;- peaktable %&gt;% dplyr::mutate(dplyr::across(dplyr::starts_with(&quot;X&quot;), ~tidyr::replace_na(., 0))) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in seq_along(pcgroups)) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;test_spectra.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra "],["example-pfas.html", "11 Example workflow: PFASs", " 11 Example workflow: PFASs A walkthrough for PFAS analysis (#fig:example_workflows_PFASs)Workflow for nontarget using XX "]]
