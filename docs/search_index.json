[["index.html", "Handbook of comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS Preface", " Handbook of comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS Thanh Wang, MTM Research Centre, Örebro University 2021-11-30 Preface This is a work-in-progress book to introduce the concepts of suspect and nontarget analysis (SSA/NTA) with focus on environmental analytical chemistry and to provide practical demonstrations for a workflow for SSA/NTA. Does not include all the vast number of platforms, software and applications that can be used for SSA/NTA. Includes the use of applications that has been developed by the author. Basic knowledge of R programming is a prerequisite to understand some of the codes The author do not take responsibility for programs or computer crashing. Please cite: "],["Intro.html", "1 Introduction and concepts 1.1 Terminologies", " 1 Introduction and concepts This is italic This is bold Demonstrating subscript: H2SO4 Superscript: 13C Inline code: library(tidyverse) ## Warning: package &#39;tibble&#39; was built under R version 4.1.2 ## Warning: package &#39;readr&#39; was built under R version 4.1.2 (#fig:target_vs_nontarget)Comparison between target and nontarget analysis Figure 1.1: Knowns and unknowns 1.1 Terminologies Blank solvent DDA: data-dependent analysis DIA: data-independent analysis EIC: extracted ion chromatogram Field blanks HRMS: high resolution mass spectrometry NTA: non-target analysis Procedural blanks Pseudo-quantification QA sample: quality assurance sample Semi-quantification Solvent blank SSA: suspect screening analysis "],["Exp_design.html", "2 Experimental design 2.1 Hypothesis 2.2 Experimental design 2.3 QA/QC measures 2.4 Data directory structure 2.5 Sampling design and collection 2.6 Collection of metadata 2.7 Chemical analysis 2.8 Data analysis 2.9 Workflow examples", " 2 Experimental design (#fig:diagram_exp_des)Design workFlow 2.1 Hypothesis xx 2.2 Experimental design - Compounds of interest? - Amendable to GC and/or LC? - Instrumentations available? 2.3 QA/QC measures 2.3.1 Recovery (Extraction efficieny) Spiking with native before extraction to evaluate the extraction efficiency. 2.3.2 Matrix effects Spiking with and after extraction to evaluate the extraction efficiency and matrix effect. Taken from (https://www.sciencedirect.com/science/article/pii/S0160412020318274#s0090) Methodology for the evaluation of matrix effect Dust samples (100 mg) were extracted and cleaned up using the method described previously, and with no standards spiked before extraction (Chen et al., 2012). The final extract containing the OPEs was reconstituted in 100 L of methanol and then aliquoted into equal volume, A and B (50 L each). Portion A was spiked with 50 L of standard solution of OPE mixtures at a concentration of 50 ng/mL per analyte. Portion B was spiked only with 50 L of methanol as reference control. Finally, the aforementioned 50 L of OPE mixture containing 50 ng/mL standards was mixed with 50 L methanol as external standard solutions (S). Six replicate dust samples were included in matrix effect assessment. By comparing the response differences of the analytes in the sub-samples A and B to the responses of the analytes in the external standard, a matrix effect (ME) value was calculated as: ME(%)=100×((Ai-Bi))/Si where Ai, Bi and Si are the chromatographic peak areas of the analyte (i) in sub-samples A and B and external standard solution (S), respectively. The analyte signals may be suppressed or enhanced by the co-eluted contents in the samples if ME (%) is lower or higher than 100%, respectively. The matrix effect results are shown in Table S2. Dilute QC extracts to investigate potential matrix effects(?). Field blanks. Procedural blanks. Solvent blanks. Procedural replicates. Triplicate injections. Should also inject the procedural replicates in triplicates. Standard reference material. Randomization. Retention time index standard. Volumetric internal standard added into the final extract to guard against small difference of extract volumes, as well as enable normalization of intensities/areas between samples and batches.Use e.g. 4,4-Dibromooctafluorobiphenyl which should not be in the samples and is stable. 2.4 Data directory structure Before starting with chemical and data analysis, you should first structure the project folder in your computer where you store all the raw and metadata. Below is a suggestion for file directory structure for your project folder. Try to use snake_case for folder and file names as space or other special characters can cause errors in various computer systems and software. YOUR_PROJECT_NAME  Project_info.xlsx  Chemicals_Database   Chemicals.xlsx   ...    Literature   Interesting_paper1.pdf   ..  Raw_files   File_info.xlsx   ..   LC_positive   LC_negative   GC_orbitrap  Results_Data_analysis   Hit_list.xlsx   Quantification.xlsx   ..   Peaklist_LC_positive   Peaklist_LC_negative  Sample_info   Sample_info.xlsx  Manuscript   Manuscript_v1.docx Here, the chemicals database could also be from an external folder or library. This is recommended to have a central database for all chemicals of interest such as suspect list, spectral libraries, etc. 2.5 Sampling design and collection xx Whats in a name? Sample names/ID Naming sample IDs might seem trivial at first but could help downstream data analysis and also to clarify your sampling design. It is important to have a uniform naming. convention and that the sample codes could also specify if a sample is a field blank, procedural blank, replicates, belong to a specific group - Dont start a sample ID with a number - Avoid using space and special characters in the file name. Space can be replaced with underscore _ instead. 2.6 Collection of metadata Metadata is the information about data. In this particular case, it is the relevant information about our samples and chemicals of interest. Examples could be the location, group, 2.7 Chemical analysis Sample order is important and should be noted in the sample information sheet. This can be important in downstream data analysis, e.g. retention time correction can be more efficiently corrected if the sample order are correctly set. 2.8 Data analysis xx 2.9 Workflow examples Iterative identification workflow (#fig:example_workflows)Workflow for nontarget using XX (#fig:example_identification)Workflow for structure elucidation and identification "],["Sample_pretreatment.html", "3 Sample pretreatment for nontarget and suspect screening 3.1 Accelerated solvent extraction (ASE)", " 3 Sample pretreatment for nontarget and suspect screening 3.1 Accelerated solvent extraction (ASE) https://tools.thermofisher.com/content/sfs/brochures/36395-TN209_V28_releasedJC042606.pdf http://apps.thermoscientific.com/media/cmd/rafa2013/13%20Galbiatti%20RAFA%202013.pdf In some samples containing moisture or water such as soil samples or food samples (animal tissue, fruits, vegetables, and so on) an additional step may be needed either before the extraction step or as a post extraction step to remove the moisture. Sample drying can be accomplished in several ways such as air drying and oven drying prior to extraction. However, these approaches are not suited when analyzing volatile or semi-volatile components as they would be removed from the sample prior to extraction or analysis. Another common method for moisture removal is by using salts such as sodium sulfate, calcium chloride, magnesium sulfate, calcium sulfate and the like. These salts tend to associate to water molecules to form hydrated salts. Sodium sulfate for example tends to clump together when water is present. Sodium sulfate is not suitable for in-cell moisture removal and accelerated solvent extraction. Sodium sulfate can dissolve in hot solvent to a certain extent and can precipitate downstream in some instances clogging the outlet frit, tubes and valves. Moreover, sodium sulfate becomes an aggregate hard lump upon water absorption and is not easy to process during sample preparation for in-cell moisture removal and extraction. "],["MS_preprocess.html", "4 Pre-processing HRMS data 4.1 Peak picking 4.2 Open tools for preprocessing 4.3 OpenMS and Toppview 4.4 MsnBase and XCMS 4.5 PatRoon 4.6 MS-DIAL 4.7 Output formats", " 4 Pre-processing HRMS data 4.1 Peak picking (#fig:PFOS isotopes)PFOS isotopic patterns (#fig:peak picking)Mass traces of PFOS and labelled standards ## Alignment ## Componentization ## Proprietary and standardized MS data format See: https://en.wikipedia.org/wiki/Mass_spectrometry_data_format 4.2 Open tools for preprocessing 4.3 OpenMS and Toppview xx https://www.youtube.com/watch?v=GuK1daIc6vo&amp;list=PL2u38g_AG4MH7yCMF06N2VW7eZOJcglh7&amp;index=5 ## MSConvert xx 4.4 MsnBase and XCMS xx 4.4.1 XCMS 4.4.2 CAMERA http://www.metabolomics-forum.com/index.php?topic=278.0 calcCiS: Calculate correlation inside samples That means correlation across the peak = is it really coeluting or not? It is correlation inside the sample; not inside a sample group. This means that camera goes back to the raw data and compares extracted ion chromatograms. The illutration in Carstens paper show this: http://pubs.acs.org/doi/abs/10.1021/ac202450g This will fail if compounds are perfectly coeluting. calcCaS: Calculate correlation accross samples They are correlated if high intensity of feature A means high intensity of feature B. The study design or sample groups are not used for this information. Look at these plots. Each dot is a sample. 4.5 PatRoon xx https://www.researchsquare.com/article/rs-36675/v1 https://rickhelmus.github.io/patRoon/articles/tutorial.html OpenMS performs peak picking and isotope grouping in one step (any idea how to turn off this?), while XCMS does not perform this step here. From Rick: For OpenMS: you can use a trick for this by setting localMZRange=0, this way OpenMS wont be able to look for isotopes. Note that its detection was more developed for natural compounds (eg proteomics, metabolomics) in mind, and that it isnt really good in grouping halogenated peaks anyway. PatRoon Docker: In linux, run: docker run rm -p 8787:8787 -u 0 -e PASSWORD=yourpasswordhere -v /home/ORUNET.ORU.SE/twg/Raw_data:/home/rstudio/Raw_data patroonorg/patroonrs /init 4.6 MS-DIAL MS2Dec: Sigma window value: 0.1 - 1.0. Smaller value will avoid clustering of peaks that are far from each other (false positive grouping). In GC-HRMS, try 0.8 to separate and deconvolute very closely coeluting peak in GC (+-1). These parameters should be tested with e.g. QC samples with known compounds to get best deconvolution parameter for your samples. MS/MS abundance cut off: increase to remove background noise 4.7 Output formats - MSnExp and XCMSnExp - MSP - MFG - CSV (for both output data or metadata) "],["suspect_screening.html", "5 Suspect screening 5.1 LIB2NIST 5.2 Listing suspects 5.3 Suspect scoring", " 5 Suspect screening 5.1 LIB2NIST X. Use LIB2NIST to convert combined msp file to NIST library. NEED TO ADD RETENTIONINDEX in comment field (see p31. of https://www.nist.gov/system/files/documents/srd/NIST1aVer22Man.pdf) Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass since the GUI tool only convert to nominal mass) NOTE TO SELF: CHECK IF THIS IS TRUE. See command line help file for arguments. IN WINDOWS: open cmd, go to the folder where LIB2NIST is and type: COMMAND: NOTE TO SELF: VERIFY THAT THE COMMAND IS CORRECT, ALSO IS IT POSSIBLE TO ADD RI? lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt; EXAMPLES: lib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\2021-05-28_MTM_HRMS_RECETOX_THERMO.msp D:\\Program\\NIST14\\ =MTM_HRMS_RECETOX_THERMO_20210528 5.2 Listing suspects 5.3 Suspect scoring https://www.waters.com/waters/fr_FR/Mass-Accuracy-and-Resolution/nav.htm?locale=fr_FR&amp;cid=10091028 Mass error (ppm): \\[\\begin{equation} ME_{ppm} = \\frac{mz_{theor} - mz_{meas}}{mz_{theor}} * 10^6 \\end{equation}\\] where mztheor is the theoretical exact mass (in u or Da) of the isotope, and mzmeas is the measured accurate mass from the instrument. RMS of isotope mz error ppm: \\[\\begin{equation} RMS_{mz} = \\sqrt{\\frac{\\sum_{i=1}^n (ME_{ppm})^2}{n}} \\end{equation}\\] At least mz of isotopes M+1, M+2 (n &gt;= 2) should be included in the calculations to give good estimate of the average RMS of isotope intensities (%): \\[\\begin{equation} RMS_{Ab} = \\sqrt{\\frac{\\sum_{i=1}^n (Ab_{theor} - Ab_{meas})^2}{n}} \\end{equation}\\] "],["mass_defect.html", "6 Mass defect plots 6.1 MDPlotR 6.2 findhalo", " 6 Mass defect plots This is a chapter about using mass defect plots to help with nontarget data 6.1 MDPlotR xx 6.2 findhalo xx "],["retention_times.html", "7 Retention time index and prediction 7.1 LC", " 7 Retention time index and prediction This is a chapter about retention time index and prediction 7.1 LC xx 7.1.1 Retip - Retention Time prediction for Metabolomics Webpage: https://www.retip.app/ "],["molecular_networks.html", "8 Molecular networks 8.1 MetGem", " 8 Molecular networks This is a chapter about molecular networks 8.1 MetGem xx 8.1.1 GC data xx Metgem webpage: https://metgem.github.io/ Metgem handbook: https://metgem.readthedocs.io/en/latest/index.html A new option was added to the input data file dialogue. When this option is activated, input spectra are treated as MS1, and thus, the parent m/z ratio is fully ignored. The molecular networks were created using MetGem 1.2.2 software (https://metgem.github.io/). EI-MS spectra were window filtered by choosing only the top 6 peaks in the ±50 Da window throughout the spectrum. Cosine scores were calculated using a m/z tolerance of 0.3 Th. Networks were then created where edges were filtered to have a cosine score above 0.7 (or 0.75 in the case of GC-EI-MS data from perfumes) and more than six matched peaks. Furthermore, edges between two nodes were kept in the network if and only if each of the nodes appeared in each others respective top 10 most similar nodes. The library spectra were filtered in the same manner as the input data. "],["library.html", "9 Library search 9.1 IN SILICO FRAGMENTATION 9.2 NEIMS 9.3 DeepEI 9.4 QCxMS (this version superseeds previous QCEIMS) 9.5 LIBRARY SEARCH 9.6 Reading mgf files in R 9.7 LIB2NIST 9.8 MSPepSearch", " 9 Library search In environmental analysis, NIST MS library is widely used to match a spectrum to a list of standard spectra. However, a major drawback of the NIST MS Search is that now all chemicals are included and all spectral ions are at unit mass (for EI spectra library, also called mainlib) Below figure shows a relatively good spectral match for a standard if only nominal or even at 0.1 decimal m/z: Figure 9.1: Spectral matching (using MS-DIAL) 9.1 IN SILICO FRAGMENTATION There are several openly available models that have recently been published to predict the fragmentation patterns of GC-EI MS. 9.1.1 Metfrag 9.1.2 Sirius CSI FingerID 9.1.3 CFM-ID In silico fragmentation: Help file: https://sourceforge.net/p/cfm-id/wiki/Home/ Use instructions: If you are using EI-MS (GC-MS) data, please use the ei_ms_model provided. Note that lpsolve55.dll must also be included in the same directory as the executables. This file can be found in the development version of LPSolve (e.g. lp_solve_5.5.2.0_dev_win32.zip), which can be downloaded from https://sourceforge.net/projects/lpsolve/files/lpsolve/5.5.2.5/lp_solve_5.5.2.5_dev_win32.zip/download. Cfm-predict COMMAND: cfm-predict.exe &lt;smiles_or_inchi_or_file&gt; &lt;prob_thresh&gt; &lt;param_file&gt; &lt;config_file&gt; &lt;annotate_fragments&gt; &lt;output_file_or_dir&gt; &lt;apply_postproc&gt; &lt;suppress_exceptions&gt; EXAMPLE (naphthalene): cfm-predict.exe InChI=1S/C10H8/c1-2-6-10-8-4-3-7-9(10)5-1/h1-8H 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp EXAMPLE (.txt file as input): cfm-predict.exe D:/Program/cfm-id-2.4_win32/test/input.txt 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp 9.2 NEIMS Help files: https://github.com/brain-research/deep-molecular-massspec 9.3 DeepEI Help files: https://github.com/hcji/DeepEI https://github.com/hcji/DeepEI/blob/master/Usage.ipynb 9.4 QCxMS (this version superseeds previous QCEIMS) This program only runs on LINUX SERVER Check QCxMS online manual for details Cehck PlotMS online manual PREPARATION - Download the latest version of QCxMS at: https://github.com/qcxms/QCxMS/releases/ - Copy the .XTBPARAM folder and the .mass_raw.agr files to /home/ORUNET.ORU.SE/twg/ - Download the lates PlotMS version at: https://github.com/qcxms/PlotMS/releases/ and copy to the same folder as QCxMS Prepare a file with the equilibrium structure of your desired molecule M. Important: This file has to be named coord and should have the TURBOMOLE coord format (tmol). In most cases you will have an .xyz file. This file can be easily converted by typing: &gt; x2t &lt;xyzfile&gt; &gt; coord if you have installed TURBOMOLE. If you do not have TURBOMOLE, you may have to write a script converting .xyz files to TUROBOMOLE coord files. Be advised that the coord file has to be in atomic units. NOTE: download the 3D conformer structure in pubchem in sdf format and then convert using openbabel -&gt; tmol. Remove the file extension .tmol to only coord. Structure needs to be optimized? Prepare an input file called qceims.in. For the input options, see section 4 or the qceims.in file in the examples folder. If no such file is prepared, default options are: run GFN1-xTB with 25 times the number of atoms in the molecule trajectories (ntraj). TO RUN QCEIMS Open bash Enable overwriting files: set +o noclobber To place the executables into your $HOME/bin directory or path, enable the QCxMS executables in the path (change if the QCxMS executables are in another folder): export PATH=/home/ORUNET.ORU.SE/twg/QCxMS/:/home/ORUNET.ORU.SE/twg/bin:/home/ORUNET.ORU.SE/twg/.local/bin:/bin:/usr/bin:/opt/thinlinc/bin:/usr/local/bin:/usr/bin/X11:/sbin:/usr/sbin:/usr/local/sbin:/snap/bin:/opt/thinlinc/bin:/opt/SPAdes/SPAdes-3.13.0-Linux/bin:/opt/mauve/mauve_snapshot_2015-02-13:/opt/parsnp/Parsnp-Linux64-v1.2:/opt/prokka/prokka-master/bin:/opt/artemis/artemis go to your folder, e.g: cd QCxMS/example/ethanol Run: qcxms Run qcxms again and check the ouput if all is ok. Executing production runs. If you want to run QCxMS locally, use the pqcxms script with -j number of parallel jobs and -t number of OMP threads: pqcxms -j &lt;integer&gt; -t &lt;integer&gt; &amp; e.g: pqcxms -j 10 -t 10 &amp; Check the status of your QCxMS run by changing to your working directory and typing getres , which will provide an output of the form: XXX runs done and written to tmpqceims.res/out which gathers the runs already finished (creates tmpqceims.res and tmpqceims.out). The final results are on qceims.out and qceims.res download an exp. EI-MS from the NIST if available and copy it to the working dir as exp.dat (take the JCAMP-DX format from their web page). - Useful for testing but not necessary. - get spectrum by plotms and plot it with xmgrace mass.agr the file .mass.agr should be in your home dir. plotms reads by default &lt;qceims.res&gt; or by plotms -f &lt;name_of_res_file&gt; any other res file. Check the consistency of the total charge. 7.2. if high resolution spectrum is needed then copy the plotms executable from the QCEIMS-HRMSplotMS folder and replace. Rename the qceims.res file to qcxms.res and run plotms. if the ratio of fragment to M+ signals is too large decrease the IEE by increasing the parameter ieeatm (default is 0.6 eV/atom) by inserting ieeatm &lt;value&gt; in qceims.in and do the parallel run again (requires an additional qceims pre-run). if the IEE is ok, increase ntraj to get better statistics and re-run (note: qceims.res is appended so delete it at this point). VERY IMPORTANT: EVERY CHANGE IN THE INPUT REQUIRES A RUN OF QCEIMS IN THE WORKING DIR BEFORE THE PARALLEL SCRIPT IS STARTED IN ORDER TO BE IN EFFECT! trajectories are in TMPQCEIMS/TMP. they are numbered by the run and the ion tracking number. (something like gmolden TMPQCEIMS/TMP.$1/trj.$1.$2 gives trajectory $1, track $2) for more QCEIMS code options (model parameters) see manual useful options for qceims: -c : check IEE but do nothing (requires M trajectory) -p : normal production (fragmentation) mode. Possible in any existing TMPQCEIMS/TMP.$1 directory. -eonly : use the requested QC (as specified in qceims.in) and do a single-point energy -e0 : same as above, charge = 0 -e1 : same as above, charge = 1 -qcp : string = path to the QC code /usr/local/bin is default) other important options in &lt;qceims.in&gt;: ip- ntraj ieeatm iseed (random number initialization to start different runs) 9.5 LIBRARY SEARCH xx 9.6 Reading mgf files in R 9.7 LIB2NIST Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass). See command line help file for arguments. COMMAND: lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt; EXAMPLES: lib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\RECETOX_GC-EI_MS_20201028.msp D:\\Program\\NIST14\\ =RECETOX_GC-EI_MS_20201028 9.8 MSPepSearch Use MSPepSearch to find similar spectra EXAMPLES: MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 10 /OnlyFound /HITS 5 /LIB D:\\Raw_data\\Dust_Florian\\GC\\test\\Mylib /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\input.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv /OutMW MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 100 /OnlyFound /HITS 5 /LIB C:\\NIST14\\NIST_contaminants_orbitrap /INP D:\\Projects\\Mexico_Air\\NIST_Mexico.msp /OUTMGF D:\\Projects\\Mexico_Air\\test\\test.mgf /OUTTAB D:\\Projects\\Mexico_Air\\test\\test.tsv MSPepSearch64.exe Gusviqh /ZI 0.01 /ZIPPM 10 /MPPM 10 /MzLimits 50 -1 /MinMF 500 /OnlyFound /HITS 5 /LIB C:\\NIST14\\LCMs_GC_Orbitrap /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\11.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv More info on commands on: https://pubs.acs.org/doi/suppl/10.1021/acs.analchem.9b03415/suppl_file/ac9b03415_si_001.pdf "],["postprocessing.html", "10 Data post-processing 10.1 Hierarchical clustering", " 10 Data post-processing ## Classyfire 10.1 Hierarchical clustering "],["example_dust.html", "11 Example workflow: indoor dust 11.1 GC orbitrap HRMS workflow 11.2 LC-HRMS using Waters MSe DIA workflow", " 11 Example workflow: indoor dust A walkthrough for indoor dust analysis (#fig:example_workflows_dust)Workflow for nontarget using XX 11.1 GC orbitrap HRMS workflow This code uses XCMS with MF -&gt; CAMERA preprocessing used in : Stettin, D.; Poulin, R.X.; Pohnert, G. Metabolomics Benefits from Orbitrap GCMSComparison of Low- and High-Resolution GCMS. Metabolites 2020, 10, 143. See the supplementary material for original code. The code was modified here to also include retention time index and also remove zero intensity peaks after peak grouping. Additional metainformation for the msp file can also be added in the extra object. library(processx) library(xcms) library(CAMERA) library(metaMS) library(dplyr) library(stringr) #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/home/ORUNET.ORU.SE/twg/Dioxinlab/GC-Orbitrap data/Florian/Dust NTA 20200513/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;/home/ORUNET.ORU.SE/twg/Windows_home/Dust_Florian/Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) mzXMLfiles &lt;- as.character(sample_info$filename) pd &lt;- data.frame(sample_name = paste0(sample_info$new_codes, &quot;.mzXML&quot;), class = sample_info$group, stringsAsFactors = FALSE) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) min.clustersize &lt;- 17 #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra useOriginalCode(TRUE) #otherwise matchedFilter will allocate a huge amount of RAM when using step = 0.001 #Refer to XCMS and CAMERA documentation for information about parameters and functions #These are the parameters used for high rez GC-Orbitrap data xs1 &lt;- xcmsSet(mzXMLfiles, phenoData = pd, method = &quot;matchedFilter&quot;, fwhm = 3, step = 0.001, steps = 2, max = 1000, snthresh = 3, mzdiff = 0.002) xs2 &lt;- group(xs1, method = &quot;density&quot;, bw = 5, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs3 &lt;- retcor(xs2, method = &quot;obiwarp&quot;) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.6, minsamp = 1, minfrac = 0, max = 1000) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs5 &lt;- fillPeaks(xs4) xs6 &lt;- xsAnnotate(xs = xs5, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;untreated_peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize #you don&#39;t need to modify anything, that run the next part as is peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in pcgroups) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;spectra_MatchedFilter20201030.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra This code uses XCMS with centWave. Check differences and skip first steps to combine both workflows #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample_xcms&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) pd &lt;- data.frame(sample_name = paste0(sample_info$analysis, &quot;.mzXML&quot;), sample_group = sample_info$group, stringsAsFactors = FALSE) mzXMLfiles &lt;- paste0(sample_info$path, &quot;/&quot;, sample_info$analysis, &quot;.mzXML&quot;) # Use subset to test pd &lt;- pd[1:2,] mzXMLfiles &lt;- mzXMLfiles[1:2] raw_data &lt;- readMSData(mzXMLfiles, pdata = new(&quot;NAnnotatedDataFrame&quot;, pd), mode = &quot;onDisk&quot;) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) #-----Find features----# # centWave params cwp &lt;- CentWaveParam(ppm = 5, peakwidth = c(3, 45), snthresh = 10, prefilter = c(1,30000), mzCenterFun = &quot;wMean&quot;, integrate = 1L, mzdiff = -0.001, fitgauss = FALSE, noise = 30000, verboseColumns = FALSE) xs1 &lt;- findChromPeaks(mzXMLfiles, param = cwp) # use model peak to evaluate process rtr &lt;- c(1440, 1460) mzr &lt;- c(340.238, 340.242) chr_raw &lt;- chromatogram(mzXMLfiles, mz = mzr, rt = rtr) chr_mzr &lt;- chromatogram(xs1, mz = mzr, rt = rtr) group_colors &lt;- paste0(brewer.pal(3, &quot;Set1&quot;)[1:2], &quot;60&quot;) sample_colors &lt;- group_colors[xs1$sample_group] #----Group features 1----# pdp &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 10, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs2 &lt;- groupChromPeaks(xs1, param = pdp) plotChromPeakDensity(chr_mzr, col = sample_colors, param = pdp) #----retention time correction----# obip &lt;- ObiwarpParam(binSize = 0.05, # need to check optimal binSize centerSample = integer(), response = 1L, distFun = &quot;cor_opt&quot;, gapInit = numeric(), gapExtend = numeric(), factorDiag = 2, factorGap = 1, localAlignment = FALSE, initPenalty = 0, subset = integer(), subsetAdjust = c(&quot;average&quot;, &quot;previous&quot;)) xs3 &lt;- adjustRtime(xs2, param = obip) # Get the base peak chromatograms bpis_adj &lt;- chromatogram(xs3, aggregationFun = &quot;max&quot;, include = &quot;none&quot;) par(mfrow = c(2, 1), mar = c(4.5, 4.2, 1, 0.5)) plot(bpis_adj) # Plot also the difference of adjusted to raw retention time. plotAdjustedRtime(xs3) par(mfrow = c(2, 1)) ## Plot the raw data plot(chr_raw) ## Extract the chromatogram from the adjusted object chr_adj &lt;- chromatogram(xs3, rt = rtr, mz = mzr) plot(chr_adj, peakType = &quot;none&quot;) #----Group features 2----# # After retention time correction, the rt values are modified and additional grouping is needed. pdp2 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 5, minFraction = 0, minSamples = 1, binSize = 0.2, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs3, param = pdp2) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp2) # iteratively decrease the binSize pdp3 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 2, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs4, param = pdp3) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp3) #----Fill missing features----# xs5 &lt;- fillChromPeaks(xs4) ## Check missing values before filling in peaks apply(featureValues(xs5, filled = FALSE), MARGIN = 2, FUN = function(z) sum(is.na(z))) ## Missing values after filling in peaks apply(featureValues(xs5), MARGIN = 2, FUN = function(z) sum(is.na(z))) #---- QC ----# # Extract chromatograms of 4 features feature_chroms &lt;- featureChromatograms(xs5, features = 10000:10004) plot(feature_chroms) boxplot(featureValues(xs5, value=&quot;into&quot;) +1, #col=as.numeric(sampclass(mtbls2Set))+1, log=&quot;y&quot;, las=2) sdThresh &lt;- 4.0 ## Filter low-standard deviation rows for plot data &lt;- log(featureValues(xs5))+1 pca.result &lt;- pca(data, nPcs=3) plotPcs(pca.result, type=&quot;loadings&quot;, #col=as.numeric(sampclass(mtbls2Set))+1 ) # It is possible to use the retention time correction and grouping step in an iterative way if needed. # Once you perform your last adjustRtime step and thus your last grouping step, you will obtain your final peak list (i.e. final list of ions) #----Annotation using CAMERA----# # Since CAMERA has not yet been ported to XCMSnExp,we need to convert to xcmsSet. # Note that the conversion only makes sense for somple XCMSnSets, # without e.g. MS level filtering (where CAMERA would then extract the wrong peaks) xs6 &lt;- as(xs5, &quot;xcmsSet&quot;) xs6 &lt;- xsAnnotate(xs = xs6, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra min.clustersize &lt;- 20 peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) # Replaces NA in intensities with zero peaktable &lt;- peaktable %&gt;% dplyr::mutate(dplyr::across(dplyr::starts_with(&quot;X&quot;), ~tidyr::replace_na(., 0))) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in seq_along(pcgroups)) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;test_spectra.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra 11.2 LC-HRMS using Waters MSe DIA workflow library(xcms) ## Loading required package: BiocParallel ## Loading required package: MSnbase ## Loading required package: BiocGenerics ## Loading required package: parallel ## ## Attaching package: &#39;BiocGenerics&#39; ## The following objects are masked from &#39;package:parallel&#39;: ## ## clusterApply, clusterApplyLB, clusterCall, clusterEvalQ, ## clusterExport, clusterMap, parApply, parCapply, parLapply, ## parLapplyLB, parRapply, parSapply, parSapplyLB ## The following objects are masked from &#39;package:dplyr&#39;: ## ## combine, intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## IQR, mad, sd, var, xtabs ## The following objects are masked from &#39;package:base&#39;: ## ## anyDuplicated, append, as.data.frame, basename, cbind, colnames, ## dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, ## grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, ## order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, ## rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply, ## union, unique, unsplit, which.max, which.min ## Loading required package: Biobase ## Welcome to Bioconductor ## ## Vignettes contain introductory material; view with ## &#39;browseVignettes()&#39;. To cite Bioconductor, see ## &#39;citation(&quot;Biobase&quot;)&#39;, and for packages &#39;citation(&quot;pkgname&quot;)&#39;. ## Loading required package: mzR ## Loading required package: Rcpp ## Warning in fun(libname, pkgname): mzR has been built against a different Rcpp version (1.0.6) ## than is installed on your system (1.0.7). This might lead to errors ## when loading mzR. If you encounter such issues, please send a report, ## including the output of sessionInfo() to the Bioc support forum at ## https://support.bioconductor.org/. For details see also ## https://github.com/sneumann/mzR/wiki/mzR-Rcpp-compiler-linker-issue. ## Loading required package: S4Vectors ## Loading required package: stats4 ## ## Attaching package: &#39;S4Vectors&#39; ## The following object is masked from &#39;package:plotly&#39;: ## ## rename ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, rename ## The following object is masked from &#39;package:tidyr&#39;: ## ## expand ## The following objects are masked from &#39;package:base&#39;: ## ## expand.grid, I, unname ## Loading required package: ProtGenerics ## ## Attaching package: &#39;ProtGenerics&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## smooth ## ## This is MSnbase version 2.18.0 ## Visit https://lgatto.github.io/MSnbase/ to get started. ## ## Attaching package: &#39;MSnbase&#39; ## The following object is masked from &#39;package:base&#39;: ## ## trimws ## ## This is xcms version 3.14.1 ## ## Attaching package: &#39;xcms&#39; ## The following object is masked from &#39;package:plotly&#39;: ## ## groups ## The following objects are masked from &#39;package:dplyr&#39;: ## ## collect, groups ## The following object is masked from &#39;package:stats&#39;: ## ## sigma library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract library(RAMClustR) ## ## Attaching package: &#39;RAMClustR&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## annotate "],["workflow-for-centroiding-of-raw-file-peak-picking-and-correlation-of-ms1-and-ms2.html", "12 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2 12.1 First convert unifi data using MSConvert 12.2 Centroiding raw data from mzML using MSnbase", " 12 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2 12.1 First convert unifi data using MSConvert Options: output format: mzML binary encoding precision: 64-bit Write index: check TPP compatibility: check use zlib compression: uncheck package in gzip: uncheck Filters: 1. TitleMaker 2. msLevel: 1-2 (need to click Add to add filter) 12.2 Centroiding raw data from mzML using MSnbase "],["example_pfas.html", "13 Example workflow: PFASs", " 13 Example workflow: PFASs A walkthrough for PFAS analysis (#fig:example_workflows_PFASs)Workflow for nontarget using XX "],["mtm-hrms-library-gc-hrms.html", "14 MTM HRMS Library: GC-HRMS 14.1 Analyze the standards using HRMS 14.2 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi conversion, see section XX) 14.3 Fill in the standard infosheet 14.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound", " 14 MTM HRMS Library: GC-HRMS This tutorial will guide you through the different steps to export the spectra information for each compound from a standard to contribute to the MTM HRMS spectral library. The overall goal is to analyze chemical standards to generate spectral fingerprints so we can combined all spectra of different standards into one spectral library. This can then be used as a suspect list which we can use to match any unknown compounds. This is a very common concept within GC screening, and the most commonly used spectral library is the NIST which has more than 100,000 compounds. The main drawback of NIST is that most of the GC spectra was recorded with nominal mass resolution. This makes spectral matching uncertain and false positives are common. The use of HRMS can reduce the uncertainty in spectral matching as well as provide clean deconvoluted spectra for real samples thus greatly reduce false positives and false negatives. To build the spectral library, we first start with the raw data file from the HRMS analysis of a standard (.raw for Thermo, etc) and then we want to generate an .msp file as the final file format. The msp file is a file format developed by NIST to store mass spectral data. For more information about this format, please see this document. The overall goal can be seen in Figure 14.1 Figure 14.1: Overall goal of the msp suspect list library If compounds were analyzed using GC, then you also need to include an alkane mix to be able to calculate the retention index (RI). In our lab, we use a mix consisting of C7-C40 alkanes. Ask Thanh for the alkane mix. You can find some representative chromatograms with retention times of the alkane mix for a 30 m DB-5ms column in the file /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/AlkaneMixRT.pptx. A solvent blank also needs to be analyzed together with the standards in order to subtract any blank signals at a later stage. The main steps of this procedure can be seen in below Figure 14.2. Figure 14.2: General workflow for spectral library The project is organized in different subfolders within the main folder folder named MTM_HRMS_LIB. Do not change the name of any folders. The template folder for the spectral library is organized as follows: MTM_HRMS_LIB  MTMxxxxx_GC-EI-FT_POSITIVE.xlsx | MTMxxxxx_LC-ESI-QTOF_POSITIVE.xlsx  .. 0_Main_Lib   MTM_HRMS_MAINLIB.xlsx   ..  1_Standard_infosheets   MTM00001_GC-EI-FT_POSITIVE.xlsx   MTM00002_GC-EI-FT_POSITIVE.xlsx | | ..  2_mzML_data  GC_CI_NEG_HRMS  GC_CI_POS_HRMS  GC_EI_HRMS | LC_ESI_NEG_HRMS  LC_ESI_POS_HRMS | 3_MSP   MTM00001_GC-EI-FT_POSITIVE_IASLDLGGHXYCEO-HWKANZROSA-N.msp   MTM00002_GC-EI-FT_POSITIVE_UPMLOUAZCHDJJD-UHFFFAOYSA-N.msp   ..  4_Massbank   MTM00001.txt | | MTM00002.txt | | ..  MSDIAL_PROJECT | MSDIAL_params | R | MTM_HRMS_database.Rmd The main folder (MTM_HRMS_LIB) contain some template info sheet that needs to be filled to provide information about the chemical standard and the analysis method. The MTM id number (MTMxxxxx) for each standard infosheet is in numeric order and must contain 8 character in total (e.g. MTM00001). Check the MTM_HRMS_MAINLIB.xlsx for the latest id number and use the next one as the new MTM id. INSTALL REQUIRED SOFTWARE Several software and packages are needed to generate the spectra library. All are open access and free to use for academic purposes. Proteowizard: We mainly use MSConvert which is bundled in the Proteowizard software package and you can download it here. MS-DIAL: used to analyze the mzML file and generate spectra. Download the latest version here. No installation is necessary so you only need to extract the downloaded zip file to your folder of choice. MS-FINDER: used to annotate the individual peaks in the spectrum and export to msp file. No installation is necessary so you only need to extract the downloaded zip file to your folder of choice. 14.1 Analyze the standards using HRMS It is recommended to analyze single standards but mixtures are also feasible to analyze if the analytes are not coeluting too close to each other. The deconvolution algorithm of MS-DIAL is able to distinguish between two peaks that are closely eluted but still have slightly different retention times and peak shapes. You should also inject a solvent blank to perform blank subtraction later in MS-DIAL. 14.2 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi conversion, see section XX) The first step is to convert the vendor software format to the open mass spectrometric data format mzML. We use MSConvert to perform this. After installing Proteowizard, open the MSConvert program. Most vendor software record the mass spectra in profile mode, but data processing of this format is usually very time consuming as well as producing very large files. Therefore, during file conversion we will also perform centroiding to make data processing faster as well as reducing the size of the mzML file. Open MSConvert. Click Browse and choose the raw file(s) you want to include and add. Choose mzML as the output format. Make sure the Output Directory is correctly set to the folder you want to store the mzML file. For this library task, you can directly choose the /MTM_HRMS_LIB/MSDIAL_PROJECT in the library folder as temporary storage. In the Filters drop down menu, select Peak Picking. For Algorithm, use Vendor for most raw files. Choose appropriate MS Levels you want to include. Use 1 - to choose all MS levels. For GC data, this is fine (since we are using EI there is only MS1). Press add and then make sure to move the peakPicking filter as the first filter as seen in below figure. If you have many files, it would be wise to increase the Files to convert in parallel to speed up the process. However, this depends on your computer processing power the number of cores it has. The other parameters should be set as seen in below Figure 14.3. Figure 14.3: MSConvert Now you can proceed with the conversion by clicking Start. After you have finished with the conversion, copy the mzML file(s) to the designated folder in MTM_HRMS_LIB/2_mzML_data/../ (where .. is the folder depending on your instrument type and analysis mode). If you want, you can now delete the original .raw file if you want to save disk space (although a copy should be available in the analysis instrument or on the server). 14.3 Fill in the standard infosheet In the main folder, choose one of the standard information sheets depending on whether you used LC or GC and the ionization mode. The content of the information sheet looks slightly different depending on LC or GC. Copy the chosen infosheet to the 1_Standard_infosheets folder. In that folder, rename the copied infosheet to the new MTM id as mentioned in previous section. The infosheet is organized in accordance to the format used by Massbank Europe. A description on the Massbank record format can be found here. It is important that you do not change any of the titles in the first column in the infosheet, as the format requirement is quite strict. Also, try not to copy text from one cell to another as it might change the underlying format of the cells (if you think you made an error, copy the template and redo again). The rows that are in bold are information that are mandatory to fill in. The ACCESSION row is the MTM id. The RECORD_TITLE will be automatically generated based on the information you filled in so you should not fill this row. COMMENT: centroided mzML file name is for internal purposes and refers to the name of the mzML file you converted and copied to the MTM_HRMS_LIB/2_mzML_data/../ folder. COMMENT: msp file name is automatically generated and will be used later to name the msp file. COMMENT: CONFIDENCE refers to how confident you are of the identification of your standard according to the Schymanski scale. Leave it as Reference Standard (Level 1), unless there are standards where you cannot distinguish or identify between different isomers in a standard. In this case, you should use Level 3. An example is Technical mixture (Level 3), where we analyzed a technical standard (usually &lt;90% purity) and several isomeric peaks can be seen in the chromatogram. In this case, I usually individually register each isomer in its own infosheet (spectral peak patterns will look very similar with slight differences and retention time is different). CH$NAME: occurs twice which means you have to input two different names for the compound in the standard, because a compound can have different names. It could be the common name specified in PubChem, the IUPAC name, trade name or the abbreviation. CH$IUPAC is the InChI and always starts with InChI=. You can find all these information for the compound by searching in PubChem. For GC compounds, you also need to fill in the AC$CHROMATOGRAPHY: KOVATS_RTI and AC$CHROMATOGRAPHY: RETENTION_TIME. These will be available later in MS-DIAL. The other rows should be quite straightforward to fill in. If you use the same method for many standards, then you can save a copy of an infosheet to use as a method template, while only updating information for each specific compound: ACCESSION, DATE, COMMENT: centroided mzML file name, CH$NAME, CH$NAME, CH$FORMULA, CH$EXACT_MASS:, CH$SMILES:, CH$IUPAC:, CH$LINK: CAS, CH$LINK: INCHIKEY The AC$CHROMATOGRAPHY: RETENTION_TIME row will be obtained later using MS-DIAL. If you use GC-MS, then you also need to fill in the AC$CHROMATOGRAPHY: KOVATS_RTI which will also be available later using MS-DIAL. Now that you have filled in most information about the compound, we can proceed to process the mzML file to extract the spectra using MS-DIAL (although you can also first process the mzML files and then fill in the information afterwards). 14.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound The graphical user interface of MS-DIAL takes some time to get used to since it is centered around detected peaks. It is important that you choose the correct parameters in the beginning since the parameters can affect the peak detection and alignment, or else you need to redo the data preprocessing again which could take long time if you are analyzing a lot of samples. When you run a large number of real samples, it is recommended to first optimize the parameters using e.g. QC samples. In this case where we analyze standards, then the default parameters with some instrument specific parameters can be used. These are found in the subfolder MSDIAL_PROJECT/MSDIAL_params/. If you want to know more details about data processing using MS-DIAL, please check the MS-DIAL online tutorial. The below steps are based on the workflow for GC-EI orbitrap data described by Price et al.. 1. In the File menu, start a new project. You must choose a file path where the mzML file(s) are located. When the data analysis is finished, several files associated with the analysis is created in the same folder. Depending on GC or LC analysis, then different parameters needs to be selected. Below Figure 14.4 shows parameters for GC analysis. GC-EI is a hard ionization and we also centroided the mzML file so these paramters needs to be specified. Figure 14.4: Starting a new project for GC analysis Click on the Advanced: add further meta data tab. The information for different instruments in our lab can be found in the file /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/Metadata.txt. If your instrument is not present then you can input these by yourself. This metadata is optional but the information will be added to the msp file later so please fill this in. When you are finished, click on next. 2. Click on the browse button and then you will select the files to process. The default file format is .abf but we want to process .mzML so choose this file format instead. You will now see the mzML file(s) in your working directory. If you want to process multiple files use Shift/Ctrl + select. Make sure your standards are designated as Sample. You should include a solvent blank which will be designated as Blank. The other columns are for post processing and not important for this spectral database workflow. You can learn more about these in the tutorial. Figure 14.5: Choosing files Click on next to the Analysis parameter settings. 3. The following instructions are for GC-EI orbitrap data, but the other processing methods are similar. Click on the Load button and select the GC_EI_Orbitrap.med2 (for GC-EI-orbtrap files) file located in the /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/ folder. This will load the preset parameters for this instrument. You can set the parameters that are suitable for your specific analysis. Click on the Advanced tab and you can also choose how many samples (threads) to process in parallel. Continue with the Peak detection tab and set an appropriate minimum peak height. This is instrument specific and also depends on the concentration of the analytes. If the Accurate MS box is not checked, then select it. Below Figure 14.6 shows the parameters for the GC-EI orbitrap. The smoothing levels and width can be set as 3 and 10 respectively for GC analysis. Figure 14.6: Peak detection parameters Continue to the MS1Dec tab. 4. The sigma window value is an important parameter which determines the efficiency of the deconvolution algorithm. The parameter depends on the instrument and Figure 14.7 shows the recommended ones for the GC orbitrap analysis of standards. From the online tutorial: The sigma window value is highly affected by the resolution of deconvolution. A higher value (0.7-1.0) will reduce the peak top resolutions, i.e. the number of resolved chromatographic peaks will be decreased. On the other hand, a lower value (0.1-0.3) may also recognize many noise chromatographic peaks. In addition, you may set a cutoff value to reduce the MS noises (see Section 3-3 of Chapter 3 of the online manual). This is the same as LC/MS part. Figure 14.7: MS1Dec parameters Continue to the Identification tab. 5. If you process GC data, we mainly want to Use retention index (RI). If the below Set button cannot be clicked, then first click on the Use retention time (min) button and the back again to the Use retention index (RI) button and then you will be able to click on the Set button next to the Index file (Figure 14.8). The Index type should be set to Alkanes since we analyzed an alkane mix. If you are using LC, then you should choose Use retention time (min), since no retention index mix is used (yet). After you clicked the Set button, you will then choose a retention index file that include the retention time (in minutes) of the different alkanes in the mixture. A template of how the format should be can be found in the file /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/xxxxxx_RTI_MSDIAL.txt. Adjust the retention time depending on your specific analysis after checking the chromatogram of the alkane mix. An example of the retention times of alkane mix can be found in the /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/AlkaneMixRT.pptx file. After you chosen the RTI file, right click on the mouse on the cell and choose autofill. Figure 14.8: Identification parameters The other parameters are not important for this standard library generation workflow and you can click on the Alignment tab. The purpose of alignment is to align all individual samples so the retention times for the same for the same compound between all samples. This is because the chromatographic retention time will slightly change between runs and batches and needs to be aligned for downstream data processing. You do not need to pay attention to this tab for the spectral library purpose. continue to the last tab Filtering. Select the Remove features based on blank informationand choose 5 fold change. This will remove any features that are lower than five times the blank samples (solvent blank in this case). Figure 14.9: Filtering parameters Now you are done and click on Finish. Sample processing might take a while depending on the processing power and the number of samples. After the peak detection and deconvolution process has finished, you should see below screen. Figure 14.10: x Double click on the sample name where your standard was analyzed (see 1 in Figure 14.10). Your screen will be switched to the Peak spot viewer tab. Each detected component will be seen as a downward pointing triangle (see 2 in Figure 14.10). You should zoom in to the peak by moving you pointer to below the x-axis and scroll to zoom in the retention time axis (3). You should now be able to see the peak more clear and click on the peak as seen in 4 in Figure 14.11. Figure 14.11: x You can then see the EIC (5) of the chosen peak to check if the peak shape is good. The extracted spectrum is shown in (6), and the retention time and retention index can be seen in (7). This is the deconvoluted spectrum and you can see the peak shape of the ion fragments with the highest intensities by choosing the EI chrom tab (8) which allows you to see if the deconvolution process has been successful (9). A note here is that the EIC shown in (5) is usually for the most intense spectral peak in the deconvoluted spectrum. When you feel that the quality is satisfactory, then you can export the spectrum to MS-FINDER by clicking on the MS FINDER search button (10). Figure 14.12: x In the new MS-FINDER window, fill in the information in (10) in Figure 14.12 for your compound. For GC-MS, in most cases the monoisotopic peak (somewhat equivalent to the precursor ion in LC mode) is not present and you can choose the fragment ion closest to the monoisotopic mass as the precursor m/z. Then choose the precursor type. For GC-EI-MS: choose [M]+. (M plus dot). After you are done, select Fragment annotation (single) in the Analysis menu (11). Afterwards, select the Fragment annotation (batch job) under the same menu. The in silico annotation of the fragment ions should now be calculated (12) and you can thereafter export the annotated spectrum as an .msp file (see 13). Copy and paste the file name that was generated in the standard infosheet you filled at the COMMENT: msp file name row. Save the file in the 3_MSP subfolder. Now you are finished with generating the msp file for your standard spectrum. Send the newly created files to Thanh: Individual infosheet(s) mzML file(s) msp file(s) The mainlib excel file as well as the combined msp file will be updated on a regular basis or upon request. The final msp file will look something like below (not including the ## sign). A note is that the retention index is not included by MS-FINDER when you export to msp file. This will be later automatically added to the combined database based on the retention index value in the infosheet for the specific standard. Therefore, it is important to check that all files have consistent MTM IDs for the same measured compound. ## NAME: 1-Methoxy-4-(4-propylcyclohexyl)cyclohexane ## SCANNUMBER: -1 ## RETENTIONTIME: 16.66233 ## RETENTIONINDEX: 1815 ## PRECURSORMZ: 208.20927 ## PRECURSORTYPE: [M]+. ## IONMODE: Positive ## SPECTRUMTYPE: Centroid ## FORMULA: C16H30O ## INCHIKEY: JMOYCPSDEMHCFG-UHFFFAOYSA-N ## INCHI: ## SMILES: CCCC1CCC(CC1)C2CCC(CC2)OC ## AUTHORS: Wang T. et al. MTM Research Centre, Orebro University ## COLLISIONENERGY: 70 ## INSTRUMENT: Q Exactive GC Orbitrap GC-MS/MS ## INSTRUMENTTYPE: GC-EI-FT ## IONIZATION: ## LICENSE: CC BY ## COMMENT: ## Num Peaks: 80 ## 55.05424 163078256 ## 56.05759 11327176 ## 57.06988 37068584 ## 58.04133 10225466 ## 59.04913 3163828 ## 65.03855 26553580 ## 66.04638 22100750 ## 67.05419 693562624 ## 68.05755 51898152 ## 69.06983 236269520 ## 70.07317 13133868 ## 71.04909 151444288 ## 72.05691 29205364 ## 73.06474 2747695 ## 77.03854 93605232 ## 78.04638 61790368 ## 79.05419 573201216 ## 80.062 208521232 ## 81.06983 1302587392 ## 82.06878 1987492 ## 82.07762 529499328 ## 83.08546 265512848 ## 84.08884 14965608 ## 85.10112 10732988 ## 91.05418 114294912 ## 92.06201 22463942 ## 93.06986 327123712 ## 94.07767 117894488 ## 95.04905 4559664 ## 95.08546 437583808 ## 96.09327 136581616 ## 97.10113 106149968 ## 98.10445 6473394 ## 103.05417 3832939 ## 105.06983 33031638 ## 106.07766 6479869 ## 107.08548 233612656 ## 108.09329 182412208 ## 109.10114 421572864 ## 110.10894 91032904 ## 111.11675 53111140 ## 112.0882 7177564 ## 113.09605 5025032 ## 115.05415 3284804 ## 117.06974 3204507 ## 119.08552 10350805 &quot;Theoretical m/z 119.086075, Mass diff 0 (0 ppm), Formula C9H11&quot; ## 120.09335 6821262 ## 121.10114 307112608 &quot;Theoretical m/z 121.10118, Mass diff 0 (0.33 ppm), SMILES CCC1CCC(C)CC1, Annotation [C9H18-5H]+, Rule of HR True&quot; ## 122.10893 282780416 ## 123.11674 393876896 ## 124.1246 151498160 ## 125.12802 22628860 ## 133.1012 7754902 &quot;Theoretical m/z 133.101725, Mass diff 0 (0 ppm), Formula C10H13&quot; ## 134.10895 3176842 &quot;Theoretical m/z 134.108995, Mass diff 0 (0.34 ppm), SMILES CCC1CCC(CC)CC1, Annotation [C10H20-6H]+, Rule of HR False&quot; ## 135.11678 219233840 &quot;Theoretical m/z 135.116821, Mass diff 0 (-0.31 ppm), SMILES C\\C=C\\C=C1\\CCC[C+]1C, Annotation [C10H15]+, Rule of HR True&quot; ## 136.12462 53804344 ## 137.13242 38836660 &quot;Theoretical m/z 137.13247, Mass diff 0 (0.37 ppm), SMILES CCCC1CCC(C)CC1, Annotation [C10H20-3H]+, Rule of HR True&quot; ## 138.14018 25185838 ## 139.14809 11154908 &quot;Theoretical m/z 139.148121, Mass diff 0 (0.22 ppm), SMILES CCCC1CCC(C)CC1, Annotation [C10H20-H]+, Rule of HR True&quot; ## 147.11674 2291410 &quot;Theoretical m/z 147.117375, Mass diff 0 (0 ppm), Formula C11H15&quot; ## 149.13238 75286480 &quot;Theoretical m/z 149.132476, Mass diff 0 (0.64 ppm), SMILES CCC1CCC(CC1)C(C)C, Annotation [C11H22-5H]+, Rule of HR True&quot; ## 150.1402 29362468 &quot;Theoretical m/z 150.140301, Mass diff 0 (0.67 ppm), SMILES CCCC1CCC(CC)CC1, Annotation [C11H22-4H]+, Rule of HR False&quot; ## 151.148 23773808 &quot;Theoretical m/z 151.148126, Mass diff 0 (0.83 ppm), SMILES CCCC1CCC(CC)CC1, Annotation [C11H22-3H]+, Rule of HR True&quot; ## 152.1515 2928506 ## 161.1324 2178252 &quot;Theoretical m/z 161.133026, Mass diff 0 (0 ppm), Formula C12H17&quot; ## 162.14021 5460352 ## 163.14796 513516864 &quot;Theoretical m/z 163.148126, Mass diff 0 (1.02 ppm), SMILES C1CCC(CC1)C2CCCCC2, Annotation [C12H22-3H]+, Rule of HR True&quot; ## 164.15137 122409664 ## 165.15913 19514364 ## 166.16704 2086600 ## 167.1429 4521269 &quot;Theoretical m/z 167.143045, Mass diff 0 (0.87 ppm), SMILES O(C)C1CCC(CC1)C(C)CC, Annotation [C11H22O-3H]+, Rule of HR True&quot; ## 177.1636 256769824 &quot;Theoretical m/z 177.163781, Mass diff 0 (1.02 ppm), SMILES CC1CCC(CC1)C2CCCCC2, Annotation [C13H24-3H]+, Rule of HR True&quot; ## 178.16693 45725136 ## 179.17041 4097704 ## 180.18657 1308408 ## 191.1792 17871500 &quot;Theoretical m/z 191.179422, Mass diff 0 (1.16 ppm), SMILES CCC1CCC(CC1)C2CCCCC2, Annotation [C14H26-3H]+, Rule of HR True&quot; ## 192.1825 2655085 ## 206.2027 271511328 ## 207.20602 42997728 ## 208.20927 3335620 "],["mtm-hrms-library-lc-hrms.html", "15 MTM HRMS Library: LC-HRMS 15.1 Analyze the standards using HRMS 15.2 Convert the raw data file from LC-HRMS in unifi to mzML using MSconvert 15.3 Fill in the standard infosheet 15.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound", " 15 MTM HRMS Library: LC-HRMS Please see the introductory section in the previous chapter regarding the MTM HRMS library using GC-HRMS. For LC analysis, the chemical standards should be run using data dependent analysis (DDA) instead of data independent analysis (DIA). For our waters G2 XS qToF instrument, the MSe is equivalent to DIA. Main distinction of MSe is the use of a ramp of collision energy in the collision cell whereas other DIA methods use a fixed collision energy. Therefore the MS2 spectra between different instruments and collision energies will also differ, which makes spectral matching more challenging in LC-HRMS compared to GC-HRMS. It is therefore common to analys the same chemical standard using different collision energies to cover the different fragment spectra (MS2) for the same compound. ADD MORE INFO ABOUT ADDUCT SELECTION This tutorial will guide you through the different steps to export the spectra information for each compound from a standard to contribute to the MTM HRMS spectral library. The project is organized in different subfolders within the main folder folder named MTM_HRMS_LIB. Do not change the name of any folders. We first start with the raw data file from the HRMS analysis of a standard and we want to generate a .msp file as a final file format. The msp file is a file format developed by NIST to store mass spectral data. For more information about this format, please see this document. The overall goal can be seen in Figure 14.1 At least one solvent blank needs to be analyzed together with the standards in order to subtract any blank signals at a later stage. The main steps of this procedure can be seen in below Figure 15.1. Figure 15.1: General workflow for spectral library The template folder for the spectral library is organized as follows: MTM_HRMS_LIB  MTMxxxxx_GC-EI-FT_POSITIVE.xlsx | MTMxxxxx_LC-ESI-QTOF_POSITIVE.xlsx  .. 0_Main_Lib   MTM_HRMS_MAINLIB.xlsx   ..  1_Standard_infosheets   MTM00001_GC-EI-FT_POSITIVE.xlsx   MTM00002_GC-EI-FT_POSITIVE.xlsx | | ..  2_mzML_data  GC_CI_NEG_HRMS  GC_CI_POS_HRMS  GC_EI_HRMS | LC_ESI_NEG_HRMS  LC_ESI_POS_HRMS | 3_MSP   MTM00001_GC-EI-FT_POSITIVE_IASLDLGGHXYCEO-HWKANZROSA-N.msp   MTM00002_GC-EI-FT_POSITIVE_UPMLOUAZCHDJJD-UHFFFAOYSA-N.msp   ..  4_Massbank   MTM00001.txt | | MTM00002.txt | | ..  MSDIAL_PROJECT | MSDIAL_params | R | MTM_HRMS_database.Rmd The main folder (MTM_HRMS_LIB) contain some template information sheet that are used to fill in information about the standard and the analysis method. The MTM id number (MTMxxxxx) for each standard infosheet is in numeric order and must contain 8 character in total. Check the MTM_HRMS_MAINLIB.xlsx for the latest id number and use the next one as the new MTM id. INSTALL REQUIRED SOFTWARE Several software and packages are needed to generate the spectra library. All are open access and free to use for academic purposes. Proteowizard: We mainly use MSConvert which is bundled in the Proteowizard software package and you can download it here. MS-DIAL: used to analyze the mzML file and generate spectra. Download the latest version here. No installation is necessary so you only need to extract the downloaded zip file to your folder of choice. MS-FINDER: used to annotate the individual peaks in the spectrum and export to msp file. 15.1 Analyze the standards using HRMS It is recommended to analyze single standards but mixtures are also feasible to analyze if the analytes are not coeluting too close to each other. The deconvolution algorithm of MS-DIAL is able to distinguish between two peaks that are closely eluted but still have slightly different retention times and peak shapes. You should also inject a solvent blank to perform blank subtraction later in MS-DIAL. 15.2 Convert the raw data file from LC-HRMS in unifi to mzML using MSconvert The first step is to convert the vendor software format to the open mass spectrometric data format mzML. We use MSConvert to perform this. The Proteowizard should be already installed in the computer connected the G2 XS qtof instrument. In Windows, search for MSConvertin the search bar and open it. Click on the Browse network resource and choose UNIFI. A new window will open which you will see the folders where all raw files are located. Choose the files you want to convert (it might take a couple of minutes before all files are loaded if the folder contain a lot of analysis files). After selecting the files, click on Open button. If you only choose one file, then you should also click on Add to add the raw file to the list (see XX). Choose mzML as the output format. Make sure the Output Directory is correctly set to the folder you want to store the mzML file. Most vendor software record the mass spectra in profile mode, but data processing of this format is usually very time consuming as well as producing very large files. Therefore, during file conversion we will also perform centroiding to make data processing faster as well as reducing the size of the mzML file. In the Filters dropdown menu, select the Peak Picking. ForAlgorithm, use Vendor for most raw files. Choose appropriate MS Levels you want to include. Use 1 - 2 to choose all MS1 (channel 1, low energy scan) and MS2 (channel 2, high energy scan). For the G2 XS qtof, there is also channel 3 which is the lock mass and not needed in this case. Click on Add and then make sure to move the peakPicking filter as the first filter as seen in below Figure 15.2. If you have many files, it would be wise to increase the Files to convert in parallel to speed up the process. However, this depends on your computer processing power the number of cores it has. The other parameters should be set as seen in below Figure 15.2. NOTE: Unfortunately, the conversion to mzML files takes a very long time for unifi files in the current computer and you should convert max 2 files. We might find a better solution for this problem in the future. Figure 15.2: MSConvert Now you can proceed with the conversion by clicking Start. After you have finished with the conversion, copy or move the mzML file(s) to the designated folder in MTM_HRMS_LIB/2_mzML_data/LC_ESI../ (where .. is the folder depending on the analysis mode, POS or NEG). 15.3 Fill in the standard infosheet In the main folder, choose one of the standard information sheets depending on whether you used LC or GC and the ionization mode. The content of the information sheet looks slightly different depending on LC or GC. Copy the chosen infosheet to the 1_Standard_infosheets folder. In that folder, rename the copied infosheet to the new MTM id as mentioned in previous section. The infosheet is organized in accordance to the format used by Massbank Europe. A description on the Massbank record format can be found here. It is important that you do not change any of the titles in the first column in the infosheet, as the format requirement is quite strict. Also, try not to copy text from one cell to another as it might change the underlying format of the cells (if you think you made an error, copy the template and redo again). The rows that are in bold are information that are mandatory to fill in. The ACCESSION row is the MTM id. The RECORD_TITLE will be automatically generated based on the information you filled in so you should not fill this row. COMMENT: centroided mzML file name is for internal purposes and refers to the name of the mzML file you converted and copied to the MTM_HRMS_LIB/2_mzML_data/../ folder. COMMENT: msp file name is automatically generated and will be used later to name the msp file. COMMENT: CONFIDENCE refers to how confident you are of the identification of your standard according to the Schymanski scale. Leave it as Reference Standard (Level 1), unless there are standards where you cannot distinguish or identify between different isomers in a standard. In this case, you should use Level 3. An example is Technical mixture (Level 3), where we analyzed a technical standard (usually &lt;90% purity) and several isomeric peaks can be seen in the chromatogram. In this case, I usually individually register each isomer in its own infosheet. CH$NAME: occurs twice which means you have to input two different names for the compound in the standard, because a compound can have different names. It could be the common name specified in PubChem, the IUPAC name, trade name or the abbreviation. CH$IUPAC is the InChI and always starts with InChI=. You can find all these information for the compound by searching in PubChem. For GC compounds, you also need to fill in the AC$CHROMATOGRAPHY: KOVATS_RTI and AC$CHROMATOGRAPHY: RETENTION_TIME. These will be available later in MS-DIAL. The other rows should be quite straightforward to fill in. If you use the same method for many standards, then you can save a copy of an infosheet to use as a method template, while only updating information for each specific compound: ACCESSION, DATE, COMMENT: centroided mzML file name, CH$NAME, CH$NAME, CH$FORMULA, CH$EXACT_MASS:, CH$SMILES:, CH$IUPAC:, CH$LINK: CAS, CH$LINK: INCHIKEY The AC$CHROMATOGRAPHY: RETENTION_TIME row will be obtained later using MS-DIAL. Now that you have filled in most information about the compound, we can proceed to process the mzML file to extract the spectra using MS-DIAL (although you can also first process the mzML files and then fill in the information afterwards). 15.4 Use MS-DIAL to perform spectral deconvolution and generate spectra for each compound The graphical user interface of MS-DIAL takes some time to get used to since it is centered around detected peaks. It is important that you choose the correct parameters in the beginning since the parameters can affect the peak detection and alignment, or else you need to redo the data preprocessing again which could take long time if you are analyzing a lot of samples. When you run a large number of real samples, it is recommended to first optimize the parameters using e.g. QC samples. In this case where we analyze standards, then the default parameters with some instrument specific parameters can be used. These are found in the subfolder MSDIAL_PROJECT/MSDIAL_params/. If you want to know more details about data processing using MS-DIAL, please check the MS-DIAL online tutorial. The below steps are based on the workflow for GC-EI orbitrap data described by Price et al. and adapted to LC-HRMS. IN THIS EXAMPLE HERE, I WILL USE ONE STANDARD OF PFAS ANALYZED IN LC-ESI IN POSITIVE MODE 1. In the File menu, start a new project. You must choose a file path where the mzML file(s) are located. When the data analysis is finished, several files associated with the analysis is created in the same folder. Depending on GC or LC analysis, then different parameters needs to be selected. Below Figure 15.3 shows parameters for LC analysis. LC-ESI is a soft ionization and the Waters G2 XS qtof instrument uses MSe which has an alternating low energy scan and high energy scan. Choose SWATH-MS and then browse to the _MSDIAL_PROJECT_paramsMSe_50_1200_params.txt file. This specifies the parameters for the MSe experiment. Since we also centroided the mzML file for both MS1 and MSMS so these parameters needs to be specified. In this example, we ran a PFAS standard in negative mode, so this ion mode was choosen in this case. Figure 15.3: Starting a new project for LC analysis Click on the Advanced: add further meta data tab. The information for different instruments in our lab can be found in the file /MTM_HRMS_LIB/MSDIAL_PROJECT/MSDIAL_params/Metadata.txt. If your instrument is not present then you can input these by yourself. This metadata is optional but the information will be added to the msp file later. When you are finished, click on next. 2. Click on the browse button and then you will select the files to process. The default file format is .abf but we want to process .mzML so choose this file format instead. You will now see the mzML file(s) in your working directory. If you want to process multiple files use Shift/Ctrl + select. Make sure your standards are designated as Sample. You should include a solvent blank which will be designated as Blank. The other columns are for post processing and not important for this spectral database workflow. You can learn more about these in the tutorial. Figure 15.4: Choosing files Click on next to the Analysis parameter settings. 3. The following instructions are for Waters G2 XS qtof in ESI negative mode, but the other processing methods are similar. Below Figure 15.5 shows the parameters for the XS qtof instrument. The MS1 and MS2 tolerance was set to 0.05 Da. Click on the Advanced tab and check the Consider Cl and Br elements. You can also choose how many samples (threads) to process in parallel. Continue with the Peak detection tab and set an appropriate minimum peak height. Use the following parameters for our spectral library purpose: Minimum peak height: 1000 amplitude. Mass slice width: 0.05 Da. This is instrument specific and also depends on the concentration of the analytes. The advanced tab can be left as default. Figure 15.5: Peak detection parameters Continue to the MS2Dec tab. 4. The sigma window value is an important parameter which determines the efficiency of the deconvolution algorithm. The parameter depends on the instrument and Figure 15.6 shows the recommended ones for the GC orbitrap analysis of standards. From the online tutorial: The sigma window value is highly affected by the resolution of deconvolution. A higher value (0.7-1.0) will reduce the peak top resolutions, i.e. the number of resolved chromatographic peaks will be decreased. On the other hand, a lower value (0.1-0.3) may also recognize many noise chromatographic peaks.. Figure 15.6: MS2Dec parameters The Identification tab is not necessary to modify for our purpose and mainly important when processing real samples (using the HRMS library as suspect list). Go on to the Adduct tab. __5._ The adduct should be chosen based on your knowledge of the ionization behavior of the standards. Most common is the [M-H]- ion for negative mode and [M+H]+ ion for positive mode. some compounds have much higher ion abundance for other adducts and therefore these can be included also. You also define your own adducts in the User-defined adduct subtab if it is not present in the list. Figure 15.7: Adduct parameters Alignment tab. The purpose of alignment is to align all individual samples so the retention times for the same for the same compound between all samples. This is because the chromatographic separation will change between runs and batches and needs to be aligned. In the Advanced subtab, check the Remove features based on blank information. A sample/blank ratio of 5 should be ok. This will remove any features that are lower than five times the blank samples (solvent blank in this case). Everything else can be as default. The Isotope tracking tab does not need to be modified in this workflow. Press Finish and the process will begin. This might take some time depending on how many samples you are processing and the processing power of the computer. Now you are done and click on Finish. After the peak detection and deconvolution process is finished, you should see below screen. Figure 15.8: x Double click on the sample name where your standard was analyzed (see 1 in Figure 15.8). Your screen will be switched to the Peak spot viewer tab. Each detected component will be seen as a downward pointing triangle (see 2 in Figure 15.8). You should zoom in to the peak by moving you pointer to below the x-axis and scroll to zoom in the retention time axis (3). You should now be able to see the peak more clear and click on the peak as seen in 4 in Figure 15.9. Figure 15.9: x You can then see the EIC (5) of the chosen peak to check if the peak shape is good. The extracted spectrum will be shown in (6), and the retention time and retention index can be seen in (7). This is the deconvoluted spectrum and you can see the peak shape of the ion fragments with the highest intensities by choosing the EI chrom tab (8) which allows you to see if the deconvolution process has been successful (9). When you feel that the quality is good, then you can export the spectrum to MS-FINDER by clicking on the MS FINDER search button (10). Figure 15.10: x In the new MS-FINDER window, fill in the information in (10) in Figure 15.10 for your compound. For GC-MS, in most cases the monoisotopic peak (somewhat equivalent to the precursor ion in LC mode) and you can choose the ion closest to the monoisotopic mass of your standard compound. Then choose the precursor type. For GC-MS: choose [M]+. (M plus dot). After you are done, select Fragment annotation (single) in the Analysis menu (11). Afterwards, select the Fragment annotation (batch job) under the same menu. The in silico annotation of the fragment ions should now be calculated (12) and you can thereafter export the annotated spectrum as an .msp file (see 13). Use the file name that was generated in the standard infosheet you filled at the COMMENT: msp file name row. Save the file in the 3_MSP subfolder. Now you are finished with generating the msp file for your standard spectrum. Send the newly created files together with the mzML files to Thanh The mainlib excel file as well as the combined msp file will be updated on a regular basis or upon request. The final msp file will look something like below (not including the ## sign). A note is that the retention index is not included by MS-FINDER when you export to msp file. This will be later automatically added to the combined database based on the retention index value in the infosheet for the specific standard. Therefore, it is important to check that all files have consistent MTM IDs for the same measured compound. NEED TO UPDATE TO LC msp "],["a-handbook-on-gc-q-exactive-orbitrap-use.html", "16 A handbook on GC Q Exactive orbitrap use 16.1 Terminologies 16.2 XCMS preprocessing", " 16 A handbook on GC Q Exactive orbitrap use Recommended to have about 10-12 scans per peak. 16.1 Terminologies Automatic Gain Control (AGC): Sets the ion injection time to maintain the optimum quantity of ions for each scan. With AGC on, the scan function consists of a prescan and an analytical scan. The split lens is used to start and stop the injection of ions into the mass analyzer. It provides a high deflection voltage most of the time so that ions are deflected into a baffle except when they are to be allowed into the C-Trap. The fast switching of the ion beam ensures the precise determination of the ion injection time that is required for AGC. This is since if too many ion are in the ion cloud going in to the orbitrap, then it will oversaturate the detector. Chemical Ionization (CI): Gas flow 16.2 XCMS preprocessing Check: A scalable workflow to characterize the human exposome, SI-11, https://www.nature.com/articles/s41467-021-25840-9#MOESM14 IPO optimization "],["reproducible-research-using-docker-containers-and-similar-tools.html", "17 Reproducible research using Docker containers and similar tools", " 17 Reproducible research using Docker containers and similar tools A list of commonly used Docker commands. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
