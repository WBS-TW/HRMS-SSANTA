[["index.html", "Comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS: a tutorial using R Preface", " Comprehensive suspect and nontarget workflows in environmental analysis using GC and LC-HRMS: a tutorial using R Thanh Wang, MTM Research Centre, Örebro University 2021-05-20 Preface This is a work-in-progress book to introduce the concepts of suspect and nontarget analysis (SSA/NTA) with focus on environmental analytical chemistry and to provide practical demonstrations for a workflow for SSA/NTA. Does not include all the vast number of platforms, software and applications that can be used for SSA/NTA. Includes the use of applications that has been developed by the author. Basic knowledge of R programming is a prerequisite to understand some of the codes The author do not take responsibility for programs or computer crashing. Please cite: "],["Intro.html", "1 Introduction and concepts 1.1 Terminologies", " 1 Introduction and concepts This is italic This is bold Demonstrating subscript: H2SO4 Superscript: 13C Inline code: library(tidyverse) (#fig:target_vs_nontarget)Comparison between target and nontarget analysis Figure 1.1: Knowns and unknowns 1.1 Terminologies - High resolution mass spectrometry - Non-target analysis - Suspect screening analysis - Semi-quantification - Pseudo-quantification - Data-dependent analysis (DDA) - Data-indenpendent analysis (DIA) "],["Exp-design.html", "2 Experimental design 2.1 Hypothesis 2.2 Experimental design 2.3 QA/QC measures 2.4 Data directory structure 2.5 Sampling design and collection 2.6 Collection of metadata 2.7 Chemical analysis 2.8 Data analysis 2.9 Workflow examples", " 2 Experimental design (#fig:diagram_exp_des)Design workFlow 2.1 Hypothesis xx 2.2 Experimental design - Compounds of interest? - Amendable to GC and/or LC? - Instrumentations available? 2.3 QA/QC measures 2.3.1 Recovery (Extraction efficieny) Spiking with native before extraction to evaluate the extraction efficiency. 2.3.2 Matrix effects Spiking with and after extraction to evaluate the extraction efficiency and matrix effect. Taken from (https://www.sciencedirect.com/science/article/pii/S0160412020318274#s0090) Methodology for the evaluation of matrix effect Dust samples (100 mg) were extracted and cleaned up using the method described previously, and with no standards spiked before extraction (Chen et al., 2012). The final extract containing the OPEs was reconstituted in 100 L of methanol and then aliquoted into equal volume, A and B (50 L each). Portion A was spiked with 50 L of standard solution of OPE mixtures at a concentration of 50 ng/mL per analyte. Portion B was spiked only with 50 L of methanol as reference control. Finally, the aforementioned 50 L of OPE mixture containing 50 ng/mL standards was mixed with 50 L methanol as external standard solutions (S). Six replicate dust samples were included in matrix effect assessment. By comparing the response differences of the analytes in the sub-samples A and B to the responses of the analytes in the external standard, a matrix effect (ME) value was calculated as: ME(%)=100×((Ai-Bi))/Si where Ai, Bi and Si are the chromatographic peak areas of the analyte (i) in sub-samples A and B and external standard solution (S), respectively. The analyte signals may be suppressed or enhanced by the co-eluted contents in the samples if ME (%) is lower or higher than 100%, respectively. The matrix effect results are shown in Table S2. Dilute QC extracts to investigate potential matrix effects(?). Field blanks. Procedural blanks. Solvent blanks. Procedural replicates. Triplicate injections. Should also inject the procedural replicates in triplicates. Standard reference material. Randomization. Retention time index standard. Volumetric internal standard added into the final extract to guard against small difference of extract volumes, as well as enable normalization of intensities/areas between samples and batches.Use e.g. 4,4-Dibromooctafluorobiphenyl which should not be in the samples and is stable. 2.4 Data directory structure Before we continue with chemical and data analysis, you should first structure the project folder in your computer where you store all the raw and metadata.Below is a suggestion for file directory structure for your project folder. Try to use underscore(_) in your folder names as space causes some errors in various systems and software. YOUR_PROJECT_NAME  Project_info.xlsx  Chemicals_Database   Chemicals.xlsx   ...    Literature   Interesting_paper1.pdf   ..  Raw_files   File_info.xlsx   ..   LC_positive   LC_negative   GC_orbitrap  Results_Data_analysis   Hit_list.xlsx   Quantification.xlsx   ..   Peaklist_LC_positive   Peaklist_LC_negative  Sample_info   Sample_info.xlsx  Manuscript   Manuscript_v1.docx Here, the chemicals database could also be from an external folder or library. This is recommended to have a central database for all chemicals of interest such as suspect list, spectral libraries, etc. 2.5 Sampling design and collection xx Whats in a name? Sample names/ID Naming sample IDs might seem trivial at first but could help downstream data analysis and also to clarify your sampling design. It is important to have a uniform naming. convention and that the sample codes could also specify if a sample is a field blank, procedural blank, replicates, belong to a specific group - Dont start a sample ID with a number - Avoid using space and special characters in the file name. Space can be replaced with underscore \"_\" instead. 2.6 Collection of metadata Metadata is the information about data. In this particular case, it is the relevant information about our samples and chemicals of interest. Examples could be the location, group, 2.7 Chemical analysis Sample order is important and should be noted in the sample information sheet. This can be important in downstream data analysis, e.g. retention time correction can be more efficiently corrected if the sample order are correctly set. 2.8 Data analysis xx 2.9 Workflow examples Iterative identification workflow (#fig:example_workflows)Workflow for nontarget using XX (#fig:example_identification)Workflow for structure elucidation and identification "],["MS-preprocess.html", "3 Pre-processing HRMS data 3.1 Peak picking", " 3 Pre-processing HRMS data 3.1 Peak picking (#fig:PFOS isotopes)PFOS isotopic patterns (#fig:peak picking)Mass traces of PFOS and labelled standards ## Alignment ## Componentization ## Proprietary and standardized MS data format See: https://en.wikipedia.org/wiki/Mass_spectrometry_data_format "],["open-tools-for-preprocessing.html", "4 Open tools for preprocessing 4.1 OpenMS and Toppview 4.2 MsnBase and XCMS 4.3 PatRoon 4.4 MS-DIAL 4.5 Output formats", " 4 Open tools for preprocessing 4.1 OpenMS and Toppview xx https://www.youtube.com/watch?v=GuK1daIc6vo&amp;list=PL2u38g_AG4MH7yCMF06N2VW7eZOJcglh7&amp;index=5 ## MSConvert xx 4.2 MsnBase and XCMS xx 4.3 PatRoon xx https://www.researchsquare.com/article/rs-36675/v1 https://rickhelmus.github.io/patRoon/articles/tutorial.html OpenMS performs peak picking and isotope grouping in one step (any idea how to turn off this?), while XCMS does not perform this step here. From Rick: For OpenMS: you can use a trick for this by setting localMZRange=0, this way OpenMS wont be able to look for isotopes. Note that its detection was more developed for natural compounds (eg proteomics, metabolomics) in mind, and that it isnt really good in grouping halogenated peaks anyway. 4.4 MS-DIAL MS2Dec: Sigma window value: 0.1 - 1.0. Smaller value will avoid clustering of peaks that are far from each other (false positive grouping). In GC-HRMS, try 0.8 to separate and deconvolute very closely coeluting peak in GC (+-1). These parameters should be tested with e.g. QC samples with known compounds to get best deconvolution parameter for your samples. MS/MS abundance cut off: increase to remove background noise 4.5 Output formats - MSnExp and XCMSnExp - MSP - MFG - CSV (for both output data or metadata) "],["suspect-screening.html", "5 Suspect screening 5.1 HRMS spectra library setup 5.2 Listing suspects 5.3 Suspect scoring", " 5 Suspect screening 5.1 HRMS spectra library setup Copy the template excel sheet for your analytical run (LC, GC, ESI, EI, POS, NEG,..) to the 1_Standard_infosheets folder. The Spectral_FileName cell will autogenerate the name for the msp file based on the filled cells. Copy this file name later for the msp file. Open MS-DIAL Perform peak peaking,. Xxx Xxx Xxx Xxx Double click on the individual file at the file navigator (click on the text of the file name) In the peak spot viewer find the peak of the standard chemical. Click on the triangle to show the deconvoluted spectrum. Retention time index is not exported to MS-FINDER. NEED TO FIX or MANUALLY COPY FROM EXCEL INFO SHEET. .. X. Use LIB2NIST to convert combined msp file to NIST library. NEED TO ADD RETENTIONINDEX in comment Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass). See command line help file for arguments. COMMAND: lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt; EXAMPLES: lib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\RECETOX_GC-EI_MS_20201028.msp D:\\Program\\NIST14\\ =RECETOX_GC-EI_MS_20201028 5.2 Listing suspects 5.3 Suspect scoring https://www.waters.com/waters/fr_FR/Mass-Accuracy-and-Resolution/nav.htm?locale=fr_FR&amp;cid=10091028 Mass error (ppm): \\[\\begin{equation} ME_{ppm} = \\frac{mz_{theor} - mz_{meas}}{mz_{theor}} * 10^6 \\end{equation}\\] where mztheor is the theoretical exact mass (in u or Da) of the isotope, and mzmeas is the measured accurate mass from the instrument. RMS of isotope mz error ppm: \\[\\begin{equation} RMS_{mz} = \\sqrt{\\frac{\\sum_{i=1}^n (ME_{ppm})^2}{n}} \\end{equation}\\] At least mz of isotopes M, M+1, M+2 (n &gt; 3) should be included in the calculations to give good estimate of the average RMS of isotope intensities (%): \\[\\begin{equation} RMS_{Ab} = \\sqrt{\\frac{\\sum_{i=1}^n (Ab_{theor} - Ab_{meas})^2}{n}} \\end{equation}\\] "],["mass-defect.html", "6 Mass defect plots 6.1 MDPlotR 6.2 findhalo", " 6 Mass defect plots This is a chapter about using mass defect plots to help with nontarget data 6.1 MDPlotR xx 6.2 findhalo xx "],["retention-times.html", "7 Retention time index and prediction 7.1 LC", " 7 Retention time index and prediction This is a chapter about retention time index and prediction 7.1 LC xx 7.1.1 Retip - Retention Time prediction for Metabolomics Webpage: https://www.retip.app/ "],["molecular-networks.html", "8 Molecular networks 8.1 MetGem", " 8 Molecular networks This is a chapter about molecular networks 8.1 MetGem xx 8.1.1 GC data xx Metgem webpage: https://metgem.github.io/ Metgem handbook: https://metgem.readthedocs.io/en/latest/index.html A new option was added to the input data file dialogue. When this option is activated, input spectra are treated as MS1, and thus, the parent m/z ratio is fully ignored. The molecular networks were created using MetGem 1.2.2 software (https://metgem.github.io/). EI-MS spectra were window filtered by choosing only the top 6 peaks in the ±50 Da window throughout the spectrum. Cosine scores were calculated using a m/z tolerance of 0.3 Th. Networks were then created where edges were filtered to have a cosine score above 0.7 (or 0.75 in the case of GC-EI-MS data from perfumes) and more than six matched peaks. Furthermore, edges between two nodes were kept in the network if and only if each of the nodes appeared in each others respective top 10 most similar nodes. The library spectra were filtered in the same manner as the input data. "],["library.html", "9 Library search 9.1 NEIMS 9.2 DeepEI 9.3 QCEIMS 9.4 LIBRARY SEARCH", " 9 Library search In environmental analysis, NIST MS library is widely used to match a spectrum to a list of standard spectra. However, a major drawback of the NIST MS Search is that now all chemicals are included and all spectral ions are at unit mass (for EI spectra library, also called mainlib) Below figure shows a relatively good spectral match for a standard if only nominal or even at 0.1 decimal m/z: Figure 9.1: Spectral matching (using MS-DIAL) ## IN SILICO FRAGMENTATION There are three different models that have recently been published to prdict the fragmentation patterns of GC-EI MS. ### MEtfrag 9.0.1 Sirius CSI FingerID 9.0.2 CFM-ID In silico fragmentation: Help file: https://sourceforge.net/p/cfm-id/wiki/Home/ Use instructions: If you are using EI-MS (GC-MS) data, please use the ei_ms_model provided. Note that lpsolve55.dll must also be included in the same directory as the executables. This file can be found in the development version of LPSolve (e.g. lp_solve_5.5.2.0_dev_win32.zip), which can be downloaded from https://sourceforge.net/projects/lpsolve/files/lpsolve/5.5.2.5/lp_solve_5.5.2.5_dev_win32.zip/download. Cfm-predict COMMAND: cfm-predict.exe &lt;smiles_or_inchi_or_file&gt; &lt;prob_thresh&gt; &lt;param_file&gt; &lt;config_file&gt; &lt;annotate_fragments&gt; &lt;output_file_or_dir&gt; &lt;apply_postproc&gt; &lt;suppress_exceptions&gt; EXAMPLE (naphthalene): cfm-predict.exe InChI=1S/C10H8/c1-2-6-10-8-4-3-7-9(10)5-1/h1-8H 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp EXAMPLE (.txt file as input): cfm-predict.exe D:/Program/cfm-id-2.4_win32/test/input.txt 0.001 D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_output.log D:/Program/cfm-id-2.4_win32/ei_nn_iso_new/param_config.txt 0 D:/Program/cfm-id-2.4_win32/test/output.msp 9.1 NEIMS Help files: https://github.com/brain-research/deep-molecular-massspec 9.2 DeepEI Help files: https://github.com/hcji/DeepEI https://github.com/hcji/DeepEI/blob/master/Usage.ipynb 9.3 QCEIMS RUN ON LINUX SERVER PREPARATION Copy the .XTBPARAM folder and the .mass_raw.agr file to /home/ORUNET.ORU.SE/twg/ Prepare a file with the equilibrium structure of your desired molecule M. Important: This file has to be named coord and should have the TURBOMOLE coord format. In most cases you will have an .xyz file. This file can be easily converted by typing: x2t &gt; coord if you have installed TURBOMOLE. If you do not have TURBOMOLE, you may have to write a script converting .xyz files to TUROBOMOLE coord files. Be advised that the coord file has to be in atomic units. CAN THIS BE DONE USING OPENBABEL? NEED TO VERIFY AND ADD STEPS Prepare an input file called qceims.in. For the input options, see section 4 or the qceims.in file in the examples folder. If no such file is prepared, default options are: run GFN1-xTB with 25 times the number of atoms in the molecule trajectories (ntraj). RUN QCEIMS set +o noclobber export PATH=/home/ORUNET.ORU.SE/twg/QCEIMS/:/home/ORUNET.ORU.SE/twg/bin:/home/ORUNET.ORU.SE/twg/.local/bin:/bin:/usr/bin:/opt/thinlinc/bin:/usr/local/bin:/usr/bin/X11:/sbin:/usr/sbin:/usr/local/sbin:/snap/bin:/opt/thinlinc/bin:/opt/SPAdes/SPAdes-3.13.0-Linux/bin:/opt/mauve/mauve_snapshot_2015-02-13:/opt/parsnp/Parsnp-Linux64-v1.2:/opt/prokka/prokka-master/bin:/opt/artemis/artemis cd QCEIMS/example/ethanol qceims run qceims again and check the ouput if all is ok. do the parallel production run (pqceims locally, q-batch on a cluster with queing system). While running you can type getres which gathers the runs already finished (creates tmpqceims.res and tmpqceims.out). The final results are on qceims.out and qceims.res download an exp. EI-MS from the NIST if available and copy it to the working dir as exp.dat (take the JCAMP-DX format from their web page). Usefull for testing but not necessary. - get spectrum by plotms and plot it with xmgrace mass.agr the file .mass.agr should be in your home dir. plotms reads by default &lt;qceims.res&gt; or by plotms -f any other res file. Check the consistency of the total charge. if the ratio of fragment to M+ signals is too large decrease the IEE by increasing the parameter ieeatm (default is 0.6 eV/atom) by inserting ieeatm in qceims.in and do the parallel run again (requires an additional qceims pre-run). if the IEE is ok, increase ntraj to get better statistics and re-run (note: qceims.res is appended so delete it at this point). VERY IMPORTANT: EVERY CHANGE IN THE INPUT REQUIRES A RUN OF QCEIMS IN THE WORKING DIR BEFORE THE PARALLEL SCRIPT IS STARTED IN ORDER TO BE IN EFFECT! trajectories are in TMPQCEIMS/TMP. they are numbered by the run and the ion tracking number. (something like gmolden TMPQCEIMS/TMP.$1/trj.$1.$2 gives trajectory $1, track $2) for more QCEIMS code options (model parameters) see manual usefull options for qceims: -c : check IEE but do nothing (requires M trajectory) -p : normal production (fragmentation) mode. Possible in any existing TMPQCEIMS/TMP.$1 directory. -eonly : use the requested QC (as specified in qceims.in) and do a single-point energy -e0 : same as above, charge = 0 -e1 : same as above, charge = 1 -qcp : string = path to the QC code /usr/local/bin is default) other important options in &lt;qceims.in&gt;: ip- ntraj ieeatm iseed (random number initialization to start different runs) 9.4 LIBRARY SEARCH xx 9.4.1 LIB2NIST Convert your library list into NIST library format using LIB2NIST command line (in order to preserve the accurate mass). See command line help file for arguments. COMMAND: lib2nist.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N &lt;path to msp file&gt; &lt;output path&gt; =&lt;new name of library&gt; EXAMPLES: lib2nist64.exe /log9 Mylib.log /OutLib /StdRounding:N /MsmsOnly:Y /AccuratePeakMZ /PrecurMzDecPlaces=keep /PeakMzDecPlaces=keep /UseSubset:N D:\\Projects\\Suspect_lists\\Spectral_databases\\RECETOX_GC-EI_MS_20201028.msp D:\\Program\\NIST14\\ =RECETOX_GC-EI_MS_20201028 9.4.2 MSPepSearch Use MSPepSearch to find similar spectra EXAMPLES: MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 10 /OnlyFound /HITS 5 /LIB D:\\Raw_data\\Dust_Florian\\GC\\test\\Mylib /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\input.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv /OutMW MSPepSearch64.exe Gusviqh /ZI 0.1 /ZIPPM 20 /MPPM 30 /MzLimits 50 -1 /MinMF 100 /OnlyFound /HITS 5 /LIB C:\\NIST14\\NIST_contaminants_orbitrap /INP D:\\Projects\\Mexico_Air\\NIST_Mexico.msp /OUTMGF D:\\Projects\\Mexico_Air\\test\\test.mgf /OUTTAB D:\\Projects\\Mexico_Air\\test\\test.tsv MSPepSearch64.exe Gusviqh /ZI 0.01 /ZIPPM 10 /MPPM 10 /MzLimits 50 -1 /MinMF 500 /OnlyFound /HITS 5 /LIB C:\\NIST14\\LCMs_GC_Orbitrap /INP D:\\Raw_data\\Dust_Florian\\GC\\test\\11.msp /OUTMGF D:\\Raw_data\\Dust_Florian\\GC\\test\\test.mgf /OUTTAB D:\\Raw_data\\Dust_Florian\\GC\\test\\test.tsv "],["postprocessing.html", "10 Data post-processing 10.1 Hierarchical clustering", " 10 Data post-processing ## Classyfire 10.1 Hierarchical clustering "],["example-dust.html", "11 Example workflow: indoor dust 11.1 GC orbitrap HRMS workflow 11.2 LC-HRMS using Waters MSe DIA workflow", " 11 Example workflow: indoor dust A walkthrough for indoor dust analysis (#fig:example_workflows_dust)Workflow for nontarget using XX 11.1 GC orbitrap HRMS workflow This code uses XCMS with MF -&gt; CAMERA preprocessing used in : Stettin, D.; Poulin, R.X.; Pohnert, G. Metabolomics Benefits from Orbitrap GCMSComparison of Low- and High-Resolution GCMS. Metabolites 2020, 10, 143. See the supplementary material for original code. The code was modified here to also include retention time index and also remove zero intensity peaks after peak grouping. Additional metainformation for the msp file can also be added in the extra object. library(processx) library(xcms) library(CAMERA) library(metaMS) library(dplyr) library(stringr) #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/home/ORUNET.ORU.SE/twg/Dioxinlab/GC-Orbitrap data/Florian/Dust NTA 20200513/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;/home/ORUNET.ORU.SE/twg/Windows_home/Dust_Florian/Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) mzXMLfiles &lt;- as.character(sample_info$filename) pd &lt;- data.frame(sample_name = paste0(sample_info$new_codes, &quot;.mzXML&quot;), class = sample_info$group, stringsAsFactors = FALSE) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) min.clustersize &lt;- 17 #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra useOriginalCode(TRUE) #otherwise matchedFilter will allocate a huge amount of RAM when using step = 0.001 #Refer to XCMS and CAMERA documentation for information about parameters and functions #These are the parameters used for high rez GC-Orbitrap data xs1 &lt;- xcmsSet(mzXMLfiles, phenoData = pd, method = &quot;matchedFilter&quot;, fwhm = 3, step = 0.001, steps = 2, max = 1000, snthresh = 3, mzdiff = 0.002) xs2 &lt;- group(xs1, method = &quot;density&quot;, bw = 5, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs3 &lt;- retcor(xs2, method = &quot;obiwarp&quot;) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.6, minsamp = 1, minfrac = 0, max = 1000) xs4 &lt;- group(xs3, method = &quot;density&quot;, bw = 2, mzwid = 0.002, minsamp = 1, minfrac = 0, max = 1000) xs5 &lt;- fillPeaks(xs4) xs6 &lt;- xsAnnotate(xs = xs5, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;untreated_peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize #you don&#39;t need to modify anything, that run the next part as is peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in pcgroups) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;peaktable_MatchedFilter.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;spectra_MatchedFilter20201030.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra This code uses XCMS with centWave. Check differences and skip first steps to combine both workflows #first define the working directory (folder with experimental group folders inside) # mzMLfiles &lt;- list.files(path = &quot;/mzXML/&quot;,pattern = &quot;.mzXML&quot;, recursive = TRUE, full.names = TRUE) # Remove files containing &quot;Hex&quot;, blank samples # mzMLfiles &lt;- mzMLfiles[-grep(&quot;Hex&quot;, mzMLfiles)] sample_info &lt;- readxl::read_xlsx(&quot;Sample_list_NTA_dust.xlsx&quot;, sheet = &quot;Sample_xcms&quot;) # filter only samples sample_info &lt;- sample_info %&gt;% dplyr::filter(!(group %in% c(&quot;blank_solvent&quot;))) pd &lt;- data.frame(sample_name = paste0(sample_info$analysis, &quot;.mzXML&quot;), sample_group = sample_info$group, stringsAsFactors = FALSE) mzXMLfiles &lt;- paste0(sample_info$path, &quot;/&quot;, sample_info$analysis, &quot;.mzXML&quot;) # Use subset to test pd &lt;- pd[1:2,] mzXMLfiles &lt;- mzXMLfiles[1:2] raw_data &lt;- readMSData(mzXMLfiles, pdata = new(&quot;NAnnotatedDataFrame&quot;, pd), mode = &quot;onDisk&quot;) # pd &lt;- pd %&gt;% dplyr::filter(sample_group != &quot;IS&quot;) %&gt;% dplyr::filter(sample_group != &quot;RTI&quot;) #-----Find features----# # centWave params cwp &lt;- CentWaveParam(ppm = 5, peakwidth = c(3, 45), snthresh = 10, prefilter = c(1,30000), mzCenterFun = &quot;wMean&quot;, integrate = 1L, mzdiff = -0.001, fitgauss = FALSE, noise = 30000, verboseColumns = FALSE) xs1 &lt;- findChromPeaks(mzXMLfiles, param = cwp) # use model peak to evaluate process rtr &lt;- c(1440, 1460) mzr &lt;- c(340.238, 340.242) chr_raw &lt;- chromatogram(mzXMLfiles, mz = mzr, rt = rtr) chr_mzr &lt;- chromatogram(xs1, mz = mzr, rt = rtr) group_colors &lt;- paste0(brewer.pal(3, &quot;Set1&quot;)[1:2], &quot;60&quot;) sample_colors &lt;- group_colors[xs1$sample_group] #----Group features 1----# pdp &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 10, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs2 &lt;- groupChromPeaks(xs1, param = pdp) plotChromPeakDensity(chr_mzr, col = sample_colors, param = pdp) #----retention time correction----# obip &lt;- ObiwarpParam(binSize = 0.05, # need to check optimal binSize centerSample = integer(), response = 1L, distFun = &quot;cor_opt&quot;, gapInit = numeric(), gapExtend = numeric(), factorDiag = 2, factorGap = 1, localAlignment = FALSE, initPenalty = 0, subset = integer(), subsetAdjust = c(&quot;average&quot;, &quot;previous&quot;)) xs3 &lt;- adjustRtime(xs2, param = obip) # Get the base peak chromatograms bpis_adj &lt;- chromatogram(xs3, aggregationFun = &quot;max&quot;, include = &quot;none&quot;) par(mfrow = c(2, 1), mar = c(4.5, 4.2, 1, 0.5)) plot(bpis_adj) # Plot also the difference of adjusted to raw retention time. plotAdjustedRtime(xs3) par(mfrow = c(2, 1)) ## Plot the raw data plot(chr_raw) ## Extract the chromatogram from the adjusted object chr_adj &lt;- chromatogram(xs3, rt = rtr, mz = mzr) plot(chr_adj, peakType = &quot;none&quot;) #----Group features 2----# # After retention time correction, the rt values are modified and additional grouping is needed. pdp2 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 5, minFraction = 0, minSamples = 1, binSize = 0.2, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs3, param = pdp2) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp2) # iteratively decrease the binSize pdp3 &lt;- PeakDensityParam( sampleGroups = pd$sample_group, bw = 2, minFraction = 0, minSamples = 1, binSize = 0.002, maxFeatures = 1000) xs4 &lt;- groupChromPeaks(xs4, param = pdp3) xs4_chrom &lt;- chromatogram(xs4, mz = mzr, rt = rtr) plotChromPeakDensity(xs4_chrom, col = sample_colors, param = pdp3) #----Fill missing features----# xs5 &lt;- fillChromPeaks(xs4) ## Check missing values before filling in peaks apply(featureValues(xs5, filled = FALSE), MARGIN = 2, FUN = function(z) sum(is.na(z))) ## Missing values after filling in peaks apply(featureValues(xs5), MARGIN = 2, FUN = function(z) sum(is.na(z))) #---- QC ----# # Extract chromatograms of 4 features feature_chroms &lt;- featureChromatograms(xs5, features = 10000:10004) plot(feature_chroms) boxplot(featureValues(xs5, value=&quot;into&quot;) +1, #col=as.numeric(sampclass(mtbls2Set))+1, log=&quot;y&quot;, las=2) sdThresh &lt;- 4.0 ## Filter low-standard deviation rows for plot data &lt;- log(featureValues(xs5))+1 pca.result &lt;- pca(data, nPcs=3) plotPcs(pca.result, type=&quot;loadings&quot;, #col=as.numeric(sampclass(mtbls2Set))+1 ) # It is possible to use the retention time correction and grouping step in an iterative way if needed. # Once you perform your last adjustRtime step and thus your last grouping step, you will obtain your final peak list (i.e. final list of ions) #----Annotation using CAMERA----# # Since CAMERA has not yet been ported to XCMSnExp,we need to convert to xcmsSet. # Note that the conversion only makes sense for somple XCMSnSets, # without e.g. MS level filtering (where CAMERA would then extract the wrong peaks) xs6 &lt;- as(xs5, &quot;xcmsSet&quot;) xs6 &lt;- xsAnnotate(xs = xs6, sample=NA, polarity = &quot;positive&quot;) xs7 &lt;- groupFWHM(xs6, sigma = 6 , perfwhm = 2, intval = &quot;maxo&quot;) xs8 &lt;- groupCorr(xs7, cor_eic_th = 0.8, calcCaS = TRUE) #how many fragments need to be in a group for it to be included in the results. 5 - trace compounds; 20 - mostly high quality spectra min.clustersize &lt;- 20 peaktable &lt;- getPeaklist(xs8, intval=&quot;into&quot;) write.csv(peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with all m/z features sorted into &quot;compounds&quot; #the following script identifies all &quot;compounds&quot; considered too small according to min.clustersize peaktable &lt;- getPeaklist(xs8, intval=&quot;maxo&quot;) # Replaces NA in intensities with zero peaktable &lt;- peaktable %&gt;% dplyr::mutate(dplyr::across(dplyr::starts_with(&quot;X&quot;), ~tidyr::replace_na(., 0))) pcgroups &lt;- sort(unique(as.numeric(peaktable$pcgroup))) lspectra &lt;- NULL extra &lt;- NULL small.clusters &lt;- NULL big.clusters &lt;- NULL n &lt;- 1 for(x in seq_along(pcgroups)) { clustersize &lt;- length(peaktable[peaktable$pcgroup==x,ncol(peaktable)]) if(clustersize &lt; as.numeric(min.clustersize)) { small.clusters &lt;- c(small.clusters, x) } else { big.clusters &lt;- c(big.clusters, x) gruppe1 &lt;- peaktable[peaktable$pcgroup==x,] gruppe1 &lt;- gruppe1[, -(2:(ncol(gruppe1)-3-(length(mzXMLfiles))))] gruppe1 &lt;- gruppe1[, -(ncol(gruppe1):(ncol(gruppe1)-2))] decider &lt;- NULL for(i in 2:ncol(gruppe1)) { decider &lt;- c(decider, sum(gruppe1[, i])) } highest &lt;- which(decider==max(decider), arr.ind = TRUE) gruppe1 &lt;- data.frame(gruppe1[, 1], gruppe1[, highest[1]+1]) colnames(gruppe1) &lt;- c(&quot;mz&quot;, &quot;int&quot;) lspectra[[n]] &lt;- gruppe1 n &lt;- n+1 } } # remove peaks with zero intensities lspectra &lt;- lapply(lspectra, function(x) {x[x$int != 0,]}) reduced.peaktable &lt;- getReducedPeaklist(xs8, method = &quot;sum&quot;, intval = &quot;into&quot;, default.adduct.info = &quot;maxint&quot;, mzrt.range = FALSE, npeaks.sum = FALSE, cleanup = FALSE) if(is.null(small.clusters)==FALSE) { for(z in small.clusters) { reduced.peaktable &lt;- reduced.peaktable[-(which(reduced.peaktable[, ncol(reduced.peaktable)]==z)), ] } } write.csv(reduced.peaktable, file = &quot;test_peaktable.csv&quot;) #This creates a peaktable .csv file with only &quot;compounds&quot; instead of m/z features extra &lt;- data.frame(Name = paste(&quot;Unknown&quot;, big.clusters, &quot;RT =&quot;,round(reduced.peaktable$rt/60, 2) ), Class = &quot;Unknown&quot;, RT = round(reduced.peaktable$rt/60, 2), stringsAsFactors = FALSE) ####KOVATS##### #Adding Kovats retention index to the extra obejct to write to msp data &lt;- data.frame(rt = extra$RT) alkaneSeries &lt;- data.frame(Num = c(11, 13, 15, 17, 19, 21, 23, 25), rt = c(4.90, 8.00, 11.13, 14.05, 16.70, 19.37, 22.45, 25.77)) RI &lt;- vector(length = nrow(data)) for (i in seq_len(nrow(data))) { m &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[1], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[7] ) n &lt;- dplyr::case_when( data$rt[i] &gt;= alkaneSeries$rt[1] &amp; data$rt[i] &lt; alkaneSeries$rt[2] ~ alkaneSeries$Num[2], data$rt[i] &gt;= alkaneSeries$rt[2] &amp; data$rt[i] &lt; alkaneSeries$rt[3] ~ alkaneSeries$Num[3], data$rt[i] &gt;= alkaneSeries$rt[3] &amp; data$rt[i] &lt; alkaneSeries$rt[4] ~ alkaneSeries$Num[4], data$rt[i] &gt;= alkaneSeries$rt[4] &amp; data$rt[i] &lt; alkaneSeries$rt[5] ~ alkaneSeries$Num[5], data$rt[i] &gt;= alkaneSeries$rt[5] &amp; data$rt[i] &lt; alkaneSeries$rt[6] ~ alkaneSeries$Num[6], data$rt[i] &gt;= alkaneSeries$rt[6] &amp; data$rt[i] &lt; alkaneSeries$rt[7] ~ alkaneSeries$Num[7], data$rt[i] &gt;= alkaneSeries$rt[7] &amp; data$rt[i] &lt;= alkaneSeries$rt[8] ~ alkaneSeries$Num[8] ) RI[i] &lt;- round(100*n + 100*(m-n) * (data$rt[i] - alkaneSeries[alkaneSeries$Num == n,]$rt)/(alkaneSeries[alkaneSeries$Num == m,]$rt - alkaneSeries[alkaneSeries$Num == n,]$rt), 0) } extra &lt;- cbind(extra, RI) ######END KOVATS###### # create the msp object with spectra and all meta information in the extra object (NAME, RETENTIONTIME, RETENTIONINDEX) export.msp &lt;- construct.msp(lspectra, extra) write.msp(export.msp, file = &quot;test_spectra.msp&quot;) #This creates a NIST MS Search compatible .msp file with all compound pseudospectra 11.2 LC-HRMS using Waters MSe DIA workflow library(xcms) ## Loading required package: Biobase ## Loading required package: BiocGenerics ## Loading required package: parallel ## ## Attaching package: &#39;BiocGenerics&#39; ## The following objects are masked from &#39;package:parallel&#39;: ## ## clusterApply, clusterApplyLB, clusterCall, clusterEvalQ, ## clusterExport, clusterMap, parApply, parCapply, parLapply, ## parLapplyLB, parRapply, parSapply, parSapplyLB ## The following objects are masked from &#39;package:dplyr&#39;: ## ## combine, intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## IQR, mad, sd, var, xtabs ## The following objects are masked from &#39;package:base&#39;: ## ## anyDuplicated, append, as.data.frame, basename, cbind, colnames, ## dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, ## grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, ## order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, ## rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply, ## union, unique, unsplit, which.max, which.min ## Welcome to Bioconductor ## ## Vignettes contain introductory material; view with ## &#39;browseVignettes()&#39;. To cite Bioconductor, see ## &#39;citation(&quot;Biobase&quot;)&#39;, and for packages &#39;citation(&quot;pkgname&quot;)&#39;. ## Loading required package: BiocParallel ## Loading required package: MSnbase ## Loading required package: mzR ## Loading required package: Rcpp ## Warning in fun(libname, pkgname): mzR has been built against a different Rcpp version (1.0.5) ## than is installed on your system (1.0.6). This might lead to errors ## when loading mzR. If you encounter such issues, please send a report, ## including the output of sessionInfo() to the Bioc support forum at ## https://support.bioconductor.org/. For details see also ## https://github.com/sneumann/mzR/wiki/mzR-Rcpp-compiler-linker-issue. ## Loading required package: S4Vectors ## Loading required package: stats4 ## ## Attaching package: &#39;S4Vectors&#39; ## The following object is masked from &#39;package:plotly&#39;: ## ## rename ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, rename ## The following object is masked from &#39;package:tidyr&#39;: ## ## expand ## The following object is masked from &#39;package:base&#39;: ## ## expand.grid ## Loading required package: ProtGenerics ## ## Attaching package: &#39;ProtGenerics&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## smooth ## ## This is MSnbase version 2.16.1 ## Visit https://lgatto.github.io/MSnbase/ to get started. ## ## Attaching package: &#39;MSnbase&#39; ## The following object is masked from &#39;package:base&#39;: ## ## trimws ## ## This is xcms version 3.12.0 ## ## Attaching package: &#39;xcms&#39; ## The following object is masked from &#39;package:plotly&#39;: ## ## groups ## The following objects are masked from &#39;package:dplyr&#39;: ## ## collect, groups ## The following object is masked from &#39;package:stats&#39;: ## ## sigma library(magrittr) ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## set_names ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract library(RAMClustR) ## ## Attaching package: &#39;RAMClustR&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## annotate "],["workflow-for-centroiding-of-raw-file-peak-picking-and-correlation-of-ms1-and-ms2.html", "12 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2 12.1 First convert unifi data using MSConvert 12.2 Centroiding raw data from mzML using MSnbase", " 12 Workflow for centroiding of raw file, peak picking and correlation of MS1 and MS2 12.1 First convert unifi data using MSConvert Options: output format: mzML binary encoding precision: 64-bit Write index: check TPP compatibility: check use zlib compression: uncheck package in gzip: uncheck Filters: 1. TitleMaker 2. msLevel: 1-2 (need to click Add to add filter) 12.2 Centroiding raw data from mzML using MSnbase "],["example-pfas.html", "13 Example workflow: PFASs", " 13 Example workflow: PFASs A walkthrough for PFAS analysis (#fig:example_workflows_PFASs)Workflow for nontarget using XX "],["a-handbook-on-gc-q-exactive-orbitrap-use.html", "14 A handbook on GC Q Exactive orbitrap use 14.1 Terminologies", " 14 A handbook on GC Q Exactive orbitrap use A walkthrough for GC Q Exactive use 14.1 Terminologies Automatic Gain Control (AGC): Sets the ion injection time to maintain the optimum quantity of ions for each scan. With AGC on, the scan function consists of a prescan and an analytical scan. The split lens is used to start and stop the injection of ions into the mass analyzer. It provides a high deflection voltage most of the time so that ions are deflected into a baffle except when they are to be allowed into the C-Trap. The fast switching of the ion beam ensures the precise determination of the ion injection time that is required for AGC. "],["step-by-step-walkthrough-on-how-to-generate-msp-files-from-raw-hrms-files.html", "15 Step-by-step walkthrough on how to generate msp files from raw HRMS files 15.1 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi, please section XX) 15.2 Fill in the standard infosheet", " 15 Step-by-step walkthrough on how to generate msp files from raw HRMS files We first start with the raw data from the analysis of a standard and we want to generate a .msp file as a final file. The msp file is a file format developed by NIST to store mass spectral data. For more information, please see this document. If compounds are analyzed using GC, then you have to include an alkane mix to be able to calculate the retention time index (RI). In our lab, we use a mix consisting of C7-C40 alkanes. Ask Thanh for the alkane mix. (#fig:diagram speclib)General workflow for export of spectral information The template folder for the spectral library is organized as follows: MTM_HRMS_LIB  MTMxxxxx_GC-EI-FT_POSITIVE.xlsx | MTMxxxxx_LC-ESI-QTOF_POSITIVE.xlsx  .. 0_Main_Lib   MTM_HRMS_MAINLIB.xlsx   ..  1_Standard_infosheets   MTM00001_GC-EI-FT_POSITIVE.xlsx   MTM00002_GC-EI-FT_POSITIVE.xlsx | | ..  2_mzML_data  GC_CI_NEG_HRMS  GC_CI_POS_HRMS  GC_EI_HRMS | LC_ESI_NEG_HRMS  LC_ESI_POS_HRMS | 3_MSP   MTM00001_GC-EI-FT_POSITIVE_IASLDLGGHXYCEO-HWKANZROSA-N.msp   Quantification.xlsx   MTM00002_GC-EI-FT_POSITIVE_UPMLOUAZCHDJJD-UHFFFAOYSA-N.msp   ..  4_Massbank   MTM00001.txt | | MTM00002.txt | | ..  MSDIAL_PROJECT | MSDIAL_params | R | MTM_HRMS_database.Rmd The main folder (MTM_HRMS_LIB) contain some template information sheet that are used to fill in information about the standard and the analysis method. The MTM id number (MTMxxxxx) for each standard infosheet is in numeric order and check the MTM_HRMS_MAINLIB.xlsx for the latest id number and use the subsequent one as the new MTM id. 15.1 Convert the raw data file from GC-HRMS analysis to .mzML using MSconvert (For unifi, please section XX) The first step is to convert the vendor software format to the open mass spectrometry format mzML. We use MSConvert to perform this. This program is bundled in the Proteowizard software package and you can download it here. After installation, open the MSConvert program. Click Browse and choose the raw files you want to include and add these. Choose mzML as the output format. Make sure the Output Directory is correctly set to the folder you want to store the mzML file. For this library task, you can directly choose the 2_mzML_data in the library folder and one of the subfolders depending on the instrument and method used to generate the raw file. In the Filters dropdown menu, select the Peak Picking. ForAlgorithm, useVendor\" for most raw files. Choose appropriate MS Levels you want to include. Use 1 - to choose all MS levels. For GC data, this is fine. Press add and then make sure to move the peakPicking filter as the first filter as seen in below figure. If you have many files, it would be wise to increase the Files to convert in parallel to speed up the process. However, this depends on your computer processing power the number of cores it has. The other parameters should be set as seen in below Figure 15.1. Figure 15.1: MSConvert After you have finished copy the mzML file(s) to the designated folder in MTM_HRMS_LIB/2_mzML_data/.. (unless you have already done it in the output directory in above step) 15.2 Fill in the standard infosheet In the main folder, choose one of the standard information sheets depending on whether you used LC or GC and the ionization mode. The content of the information sheet looks slightly different depending on LC or GC. Copy the chosen infosheet to the 1_Standard_infosheets folder. In that folder, rename the copied infosheet to the new MTM id as mentioned in previous section. The infosheet is organized in accordance to the format used by Massbank Europe. A description on the Massbank record format can be found here. It is important that you do not change any of the titles in the first column in the infosheet, as the format requirement is quite strict. Also, try not to copy text from one cell to another as it might change the underlying format of the cells (if you think you made an error, copy the template and redo again). The rows that are in bold are information that are mandatory to fill in. The ACCESSION row is the MTM id, the RECORD_TITLE will be automatically generated based on the information you filled in so you will not fill this row. COMMENT: centroided mzML file name is for internal purposes and refers to the name of the mzML file you converted. COMMENT: msp file name is automatically generated and will be used later to name the msp file. COMMENT: CONFIDENCE refers to how confident you are of the identification of your standard according to the Schymanski scale. Leave it as Reference Standard (Level 1), unless there are standards where you cannot distinguish or identify between different isomers in a standard. In this case, you should use Level 3. An example is Technical mixture (Level 3). CH\\$NAME: occurs twice which means you have to input two different names for the compound in the standard, because a compound can have different names. It could be the common name specified in PubChem, the IUPAC name, trade name or the abbreviation. The CH$IUPAC is the InChI which starts with InChI=. You can find all these information for the compound by searching in PubChem. For GC compounds, you also need to fill in the AC$CHROMATOGRAPHY: KOVATS_RTI and AC$CHROMATOGRAPHY: RETENTION_TIME. These will be available later in MS-DIAL. The other rows should be quite straightforward to fill in. If you use the same method for many standards, then you can save a copy of an infosheet to use as a method template, while only filling information for the different compounds: ACCESSION, DATE, COMMENT: centroided mzML file name, CH$NAME, CH$NAME, CH$FORMULA:, CH$EXACT_MASS:, CH$SMILES:, CH$IUPAC:, CH$LINK: CAS, CH$LINK: INCHIKEY "]]
